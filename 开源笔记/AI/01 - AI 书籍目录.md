### [白话大数据与机器学习](https://item.jd.com/11932929.html)

```text
第1章大数据产业1
1.1大数据产业现状1
1.2对大数据产业的理解2
1.3大数据人才3
1.3.1供需失衡3
1.3.2人才方向3
1.3.3环节和工具5
1.3.4门槛障碍6
1.4小结8
第2章步入数据之门9
2.1什么是数据9
2.2什么是信息10
2.3什么是算法12
2.4统计、概率和数据挖掘13
2.5什么是商业智能13
2.6小结14
第3章排列组合与古典概型15
3.1排列组合的概念16
3.1.1公平的决断——扔硬币16
3.1.2非古典概型17
3.2排列组合的应用示例18
3.2.1双色球彩票18
3.2.2购车摇号20
3.2.3德州扑克21
3.3小结25
第4章统计与分布27
4.1加和值、平均值和标准差27
4.1.1加和值28
4.1.2平均值29
4.1.3标准差30
4.2加权均值32
4.2.1混合物定价32
4.2.2决策权衡34
4.3众数、中位数35
4.3.1众数36
4.3.2中位数37
4.4欧氏距离37
4.5曼哈顿距离39
4.6同比和环比41
4.7抽样43
4.8高斯分布45
4.9泊松分布49
4.10伯努利分布52
4.11小结54
第5章指标55
5.1什么是指标55
5.2指标化运营58
5.2.1指标的选择58
5.2.2指标体系的构建62
5.3小结63
第6章信息论64
6.1信息的定义64
6.2信息量65
6.2.1信息量的计算65
6.2.2信息量的理解66
6.3香农公式68
6.4熵70
6.4.1热力熵70
6.4.2信息熵72
6.5小结75
第7章多维向量空间76
7.1向量和维度76
7.1.1信息冗余77
7.1.2维度79
7.2矩阵和矩阵计算80
7.3数据立方体83
7.4上卷和下钻85
7.5小结86
第8章回归87
8.1线性回归87
8.2拟合88
8.3残差分析94
8.4过拟合99
8.5欠拟合100
8.6曲线拟合转化为线性拟合101
8.7小结104
第9章聚类105
9.1K-Means算法106
9.2有趣模式109
9.3孤立点110
9.4层次聚类110
9.5密度聚类113
9.6聚类评估116
9.6.1聚类趋势117
9.6.2簇数确定119
9.6.3测定聚类质量121
9.7小结124
第10章分类125
10.1朴素贝叶斯126
10.1.1天气的预测128
10.1.2疾病的预测130
10.1.3小结132
10.2决策树归纳133
10.2.1样本收集135
10.2.2信息增益136
10.2.3连续型变量137
10.3随机森林140
10.4隐马尔可夫模型141
10.4.1维特比算法144
10.4.2前向算法151
10.5支持向量机SVM154
10.5.1年龄和好坏154
10.5.2“下刀”不容易157
10.5.3距离有多远158
10.5.4N维度空间中的距离159
10.5.5超平面怎么画160
10.5.6分不开怎么办160
10.5.7示例163
10.5.8小结164
10.6遗传算法164
10.6.1进化过程164
10.6.2算法过程165
10.6.3背包问题165
10.6.4极大值问题173
10.7小结181
第11章关联分析183
11.1频繁模式和Apriori算法184
11.1.1频繁模式184
11.1.2支持度和置信度185
11.1.3经典的Apriori算法187
11.1.4求出所有频繁模式190
11.2关联分析与相关性分析192
11.3稀有模式和负模式193
11.4小结194
第12章用户画像195
12.1标签195
12.2画像的方法196
12.2.1结构化标签196
12.2.2非结构化标签198
12.3利用用户画像203
12.3.1割裂型用户画像203
12.3.2紧密型用户画像204
12.3.3到底“像不像”204
12.4小结205
第13章推荐算法206
13.1推荐思路206
13.1.1贝叶斯分类206
13.1.2利用搜索记录207
13.2User-basedCF209
13.3Item-basedCF211
13.4优化问题215
13.5小结217
第14章文本挖掘218
14.1文本挖掘的领域218
14.2文本分类219
14.2.1Rocchio算法220
14.2.2朴素贝叶斯算法223
14.2.3K-近邻算法225
14.2.4支持向量机SVM算法226
14.3小结227
第15章人工神经网络228
15.1人的神经网络228
15.1.1神经网络结构229
15.1.2结构模拟230
15.1.3训练与工作231
15.2FANN库简介233
15.3常见的神经网络235
15.4BP神经网络235
15.4.1结构和原理236
15.4.2训练过程237
15.4.3过程解释240
15.4.4示例240
15.5玻尔兹曼机244
15.5.1退火模型244
15.5.2玻尔兹曼机245
15.6卷积神经网络247
15.6.1卷积248
15.6.2图像识别249
15.7深度学习255
15.8小结256
第16章大数据框架简介257
16.1著名的大数据框架257
16.2Hadoop框架258
16.2.1MapReduce原理259
16.2.2安装Hadoop261
16.2.3经典的WordCount264
16.3Spark框架269
16.3.1安装Spark270
16.3.2使用Scala计算WordCount271
16.4分布式列存储框架272
16.5PrestoDB——神奇的CLI273
16.5.1Presto为什么那么快273
16.5.2安装Presto274
16.6小结277
第17章系统架构和调优278
17.1速度——资源的配置278
17.1.1思路一：逻辑层面的优化279
17.1.2思路二：容器层面的优化279
17.1.3思路三：存储结构层面的优化280
17.1.4思路四：环节层面的优化280
17.1.5资源不足281
17.2稳定——资源的可用282
17.2.1借助云服务282
17.2.2锁分散282
17.2.3排队283
17.2.4谨防“雪崩”283
17.3小结285
第18章数据解读与数据的价值286
18.1运营指标286
18.1.1互联网类型公司常用指标287
18.1.2注意事项288
18.2AB测试289
18.2.1网页测试290
18.2.2方案测试290
18.2.3灰度发布292
18.2.4注意事项293
18.3数据可视化295
18.3.1图表295
18.3.2表格299
18.4多维度——大数据的灵魂299
18.4.1多大算大299
18.4.2大数据网络300
18.4.3去中心化才能活跃301
18.4.4数据会过剩吗302
18.5数据变现的场景303
18.5.1数据价值的衡量的讨论303
18.5.2场景1：征信数据307
18.5.3场景2：宏观数据308
18.5.4场景3：画像数据309
18.6小结310
附录AVMwareWorkstation的安装311
附录BCentOS虚拟机的安装方法314
附录CPython语言简介318
附录DScikit-learn库简介323
附录EFANNforPython安装324
附录F群众眼中的大数据325
写作花絮327
参考文献329
```

### [白话深度学习与TensorFlow](https://item.jd.com/12228460.html)
```text
本书赞誉
序
前　言
基　础　篇
第1章　机器学习是什么 2
1.1　聚类 4
1.2　回归 5
1.3　分类 8
1.4　综合应用 10
1.5　小结 14
第2章　深度学习是什么 15
2.1　神经网络是什么 15
2.1.1　神经元 16
2.1.2　激励函数 19
2.1.3　神经网络 24
2.2　深度神经网络 25
2.3　深度学习为什么这么强 28
2.3.1　不用再提取特征 28
2.3.2　处理线性不可分 29
2.4　深度学习应用 30
2.4.1　围棋机器人——AlphaGo 30
2.4.2　被教坏的少女——Tai.ai 32
2.4.3　本田公司的大宝贝——
ASIMO 33
2.5　小结 37
第3章　TensorFlow框架特性与安装 38
3.1　简介 38
3.2　与其他框架的对比 39
3.3　其他特点 40
3.4　如何选择好的框架 44
3.5　安装TensorFlow 45
3.6　小结 46
原理与实践篇
第4章　前馈神经网络 50
4.1　网络结构 50
4.2　线性回归的训练 51
4.3　神经网络的训练 75
4.4　小结 79
第5章　手写板功能 81
5.1　MNIST介绍 81
5.2　使用TensorFlow完成实验 86
5.3　神经网络为什么那么强 92
5.3.1　处理线性不可分 93
5.3.2　挑战“与或非” 95
5.3.3　丰富的VC——强大的空间
划分能力 98
5.4　验证集、测试集与防止过拟合 99
5.5　小结 102
第6章　卷积神经网络 103
6.1　与全连接网络的对比 103
6.2　卷积是什么 104
6.3　卷积核 106
6.4　卷积层其他参数 108
6.5　池化层 109
6.6　典型CNN网络 110
6.7　图片识别 114
6.8　输出层激励函数——SOFTMAX 116
6.8.1　SOFTMAX 116
6.8.2　交叉熵 117
6.9　小试牛刀——卷积网络做图片分类 124
6.10　小结 138
第7章　综合问题 139
7.1　并行计算 139
7.2　随机梯度下降 142
7.3　梯度消失问题 144
7.4　归一化 147
7.5　参数初始化问题 149
7.6　正则化 151
7.7　其他超参数 155
7.8　不唯一的模型 156
7.9　DropOut 157
7.10　小结 158
第8章　循环神经网络 159
8.1　隐马尔可夫模型 159
8.2　RNN和BPTT算法 163
8.2.1　结构 163
8.2.2　训练过程 163
8.2.3　艰难的误差传递 165
8.3　LSTM算法 167
8.4　应用场景 171
8.5　实践案例——自动文本生成 174
8.5.1　RNN工程代码解读 174
8.5.2　利用RNN学习莎士比亚剧本 183
8.5.3　利用RNN学习维基百科 184
8.6　实践案例——聊天机器人 185
8.7　小结 196
扩　展　篇
第9章　深度残差网络 198
9.1　应用场景 198
9.2　结构解释与数学推导 200
9.3　拓扑解释 205
9.4　Github示例 207
9.5　小结 207
第10章　受限玻尔兹曼机 209
10.1　结构 209
10.2　逻辑回归 210
10.3　最大似然度 212
10.4　最大似然度示例 214
10.5　损失函数 215
10.6　应用场景 216
10.7　小结 216
第11章　强化学习 217
11.1　模型核心 218
11.2　马尔可夫决策过程 219
11.2.1　用游戏开刀 221
11.2.2　准备工作 223
11.2.3　训练过程 224
11.2.4　问题 226
11.2.5　Q-Learning算法 228
11.3　深度学习中的Q-Learning——DQN 231
11.3.1　OpenAI Gym 234
11.3.2　Atari游戏 237
11.4　小结 238
第12章　对抗学习 239
12.1　目的 239
12.2　训练模式 240
12.2.1　二元极小极大博弈 240
12.2.2　训练 242
12.3　CGAN 244
12.4　DCGAN 247
12.5　小结 252
第13章　有趣的深度学习应用 254
13.1　人脸识别 254
13.2　作诗姬 259
13.3　梵高附体 264
13.3.1　网络结构 265
13.3.2　内容损失 268
13.3.3　风格损失 270
13.3.4　系数比例 271
13.3.5　代码分析 272
13.4　小结 279
附录A　VMware Workstation的安装 280
附录B　Ubuntu虚拟机的安装 284
附录C　Python语言简介 290
附录D　安装Theano 296
附录E　安装Keras 297
附录F　安装CUDA 298
参考文献 303
```

### [白话机器学习算法(图灵出品)](https://item.jd.com/12557550.html)

```text
第 1章 基础知识 1
1．1　准备数据　1
1．1．1　数据格式　1
1．1．2　变量类型　2
1．1．3　变量选择　3
1．1．4　特征工程　3
1．1．5　缺失数据　4
1．2　选择算法　4
1．2．1　无监督学习　5
1．2．2　监督学习　6
1．2．3　强化学习　7
1．2．4　注意事项　7
1．3　参数调优　7
1．4　评价模型　9
1．4．1　分类指标　9
1．4．2　回归指标　10
1．4．3　验证　10
1．5　小结　11
第　2章 k均值聚类　13
2．1　找出顾客群　13
2．2　示例：影迷的性格特征　13
2．3　定义群组　16
2．3．1　有多少个群组　16
2．3．2　每个群组中有谁　17
2．4　局限性　18
2．5　小结　19
第3章　主成分分析　21
3．1　食物的营养成分　21
3．2　主成分　22
3．3　示例：分析食物种类　24
3．4　局限性　27
3．5　小结　29
第4章　关联规则　31
4．1　发现购买模式　31
4．2　支持度、置信度和提升度　31
4．3　示例：分析杂货店的销售数据　33
4．4　先验原则　35
4．4．1　寻找具有高支持度的项集　36
4．4．2　寻找具有高置信度或高提升度的关联规则　37
4．5　局限性　37
4．6　小结　37
第5章　社会网络分析　39
5．1　展现人际关系　39
5．2　示例：国际贸易　40
5．3　Louvain方法　42
5．4　PageRank算法　43
5．5　局限性　46
5．6　小结　47
第6章　回归分析　49
6．1　趋势线　49
6．2　示例：预测房价　49
6．3　梯度下降法　52
6．4　回归系数　54
6．5　相关系数　55
6．6　局限性　56
6．7　小结　57
第7章　k最近邻算法和异常检测　59
7．1　食品检测　59
7．2　物以类聚，人以群分　60
7．3　示例：区分红白葡萄酒　61
7．4　异常检测　62
7．5　局限性　63
7．6　小结　63
第8章　支持向量机　65
8．1　医学诊断　65
8．2　示例：预测心脏病　65
8．3　勾画最佳分界线　66
8．4　局限性　69
8．5　小结　69
第9章　决策树　71
9．1　预测灾难幸存者　71
9．2　示例：逃离泰坦尼克号　72
9．3　生成决策树　73
9．4　局限性　74
9．5　小结　75
第　10章 随机森林　77
10．1　集体智慧　77
10．2　示例：预测犯罪行为　77
10．3　集成模型　81
10．4　自助聚集法　82
10．5　局限性　83
10．6　小结　84
第　11章 神经网络　85
11．1　建造人工智能大脑　85
11．2　示例：识别手写数字　86
11．3　神经网络的构成　89
11．4　激活规则　91
11．5　局限性　92
11．6　小结　94
第　12章 A/B测试和多臂老虎机　95
12．1　初识A/B测试　95
12．2　A/B测试的局限性　95
12．3　epsilon递减策略　96
12．4　示例：多臂老虎机　97
12．5　胜者为先　99
12．6　epsilon递减策略的局限性　99
12．7　小结　100
附录A　无监督学习算法概览　101
附录B　监督学习算法概览　102
附录C　调节参数列表　103
附录D　更多评价指标　104
术语表　107
关于作者　114
```

### [深度学习的数学](https://e.jd.com/30562037.html?ebook=1)

```text
第1章　神经网络的思想
1 - 1　神经网络和深度学习　　2
1 - 2　神经元工作的数学表示　　6
1 - 3　激活函数：将神经元的工作一般化　　12
1 - 4　什么是神经网络　　18
1 - 5　用恶魔来讲解神经网络的结构　　23
1 - 6　将恶魔的工作翻译为神经网络的语言　　31
1 - 7　网络自学习的神经网络　　36
第2章　神经网络的数学基础
2 - 1　神经网络所需的函数　　40
2 - 2　有助于理解神经网络的数列和递推关系式　　46
2 - 3　神经网络中经常用到的Σ符号　　51
2 - 4　有助于理解神经网络的向量基础　　53
2 - 5　有助于理解神经网络的矩阵基础　　61
2 - 6　神经网络的导数基础　　65
2 - 7　神经网络的偏导数基础　　72
2 - 8　误差反向传播法必需的链式法则　　76
2 - 9　梯度下降法的基础：多变量函数的近似公式　　80
2 - 10　梯度下降法的含义与公式　　83
2 - 11　用Excel 体验梯度下降法　　91
2 - 12　最优化问题和回归分析　　94
第3章　神经网络的最优化
3 - 1　神经网络的参数和变量　　102
3 - 2　神经网络的变量的关系式　　111
3 - 3　学习数据和正解　　114
3 - 4　神经网络的代价函数　　119
3 - 5　用Excel体验神经网络　　127
第4章　神经网络和误差反向传播法
4 - 1　梯度下降法的回顾　　134
4 - 2　神经单元误差　　141
4 - 3　神经网络和误差反向传播法　　146
4 - 4　用Excel体验神经网络的误差反向传播法　　153
第5章　深度学习和卷积神经网络
5 - 1　小恶魔来讲解卷积神经网络的结构　　168
5 - 2　将小恶魔的工作翻译为卷积神经网络的语言　　174
5 - 3　卷积神经网络的变量关系式　　180
5 - 4　用Excel体验卷积神经网络　　193
5 - 5　卷积神经网络和误差反向传播法　　200
5 - 6　用Excel体验卷积神经网络的误差反向传播法　　212
附录
A　训练数据（1）　　222
B　训练数据（2）　　223
C　用数学式表示模式的相似度　　225
```

### [白话强化学习与PyTorch(博文视点出品)](https://item.jd.com/12652422.html)

```text
传统篇
第1章　强化学习是什么 2
1.1　题设 3
1.1.1　多智能才叫智能 5
1.1.2　人工智能的定义 5
1.2　强化学习的研究对象 7
1.2.1　强化学习的应用场合 7
1.2.2　强化学习的建模 11
1.3　本章小结 17
第2章　强化学习的脉络 18
2.1　什么是策略 18
2.2　什么样的策略是好的策略 19
2.3　什么是模型 21
2.4　如何得到一个好的策略 23
2.4.1　直接法 23
2.4.2　间接法 25
2.5　马尔可夫决策过程 29
2.5.1　状态转移 30
2.5.2　策略与评价 31
2.5.3　策略优化 36
2.6　Model-Based和Model-Free 36
2.6.1　Model-Based 36
2.6.2　规划问题 37
2.6.3　Model-Free 38
2.7　本章小结 38
第3章　动态规划 40
3.1　状态估值 40
3.2　策略优化 42
3.3　本章小结 43
第4章　蒙特卡罗法 45
4.1　历史由来 45
4.2　状态估值 47
4.3　两种估值方法 49
4.3.1　首次访问蒙特卡罗策略估值 49
4.3.2　每次访问蒙特卡罗策略估值 49
4.3.3　增量平均 50
4.4　弊端 51
4.5　本章小结 52
第5章　时间差分 53
5.1　SARSA算法 53
5.1.1　SARSA算法的伪代码 54
5.1.2　SARSA算法的优点和缺点 57
5.2　Q-Learning算法 57
5.2.1　Q-Learning算法的伪代码 58
5.2.2　Q-Learning算法的优点和缺点 59
5.3　On-Policy和Off-Policy 61
5.4　On-Line学习和Off-Line学习 62
5.5　比较与讨论 63
5.6　本章小结 65

现代篇
第6章　深度学习 68
6.1　PyTorch简介 69
6.1.1　历史渊源 70
6.1.2　支持 71
6.2　神经元 74
6.3　线性回归 77
6.4　激励函数 80
6.4.1　Sigmoid函数 81
6.4.2　Tanh函数 82
6.4.3　ReLU函数 82
6.4.4　Linear函数 83
6.5　神经网络 84
6.6　网络训练 85
6.6.1　输入 86
6.6.2　输出 86
6.6.3　网络结构 87
6.6.4　损失函数 88
6.6.5　求解极小值 90
6.6.6　线性回归 90
6.6.7　凸函数 93
6.6.8　二元（多元）凸函数 98
6.6.9　导数补充 101
6.6.10　导数怎么求 103
6.6.11　“串联”的神经元 105
6.6.12　模型的工作 107
6.6.13　理解损失函数 108
6.7　深度学习的优势 108
6.7.1　线性和非线性的叠加 109
6.7.2　不用再提取特征 111
6.7.3　处理线性不可分 112
6.8　手写数字识别公开数据集 114
6.9　全连接网络 117
6.9.1　输入与输出 118
6.9.2　代码解读 119
6.9.3　运行结果 125
6.10　卷积神经网络 125
6.10.1　代码解读 125
6.10.2　理解卷积神经网络的结构 132
6.10.3　卷积核的结构 134
6.11　循环神经网络 135
6.11.1　网络结构 136
6.11.2　应用案例 140
6.11.3　代码解读 143
6.12　其他注意事项 148
6.12.1　并行计算 148
6.12.2　梯度消失和梯度爆炸 152
6.12.3　归一化 157
6.12.4　超参数的设置 159
6.12.5　正则化 161
6.12.6　不唯一的模型 170
6.13　深度神经网络的发展趋势 171
6.14　本章小结 178
第7章　Gym——不要钱的试验场 180
7.1　简介 180
7.2　安装 182
7.3　类别 183
7.4　接口 188
7.5　本章小结 191
第8章　DQN算法族 192
8.1　2013版DQN 192
8.1.1　模型结构 192
8.1.2　训练过程 195
8.1.3　Replay Memory 197
8.1.4　小结 198
8.2　2015版DQN 198
8.2.1　模型结构 198
8.2.2　训练过程 199
8.2.3　Target网络 200
8.2.4　小结 201
8.3　Double DQN 201
8.3.1　模型结构 202
8.3.2　训练过程 202
8.3.3　效果 203
8.3.4　小结 204
8.4　Dueling DQN 204
8.4.1　模型结构 205
8.4.2　效果 207
8.4.3　小结 208
8.5　优先回放DQN 208
8.6　本章小结 209
第9章　PG算法族 211
9.1　策略梯度 211
9.2　DPG 213
9.3　Actor-Critic 214
9.4　DDPG 214
9.5　本章小结 218
第10章　A3C 219
10.1　模型结构 219
10.1.1　A3C Q-Learning 219
10.1.2　A3C Actor-Critic 222
10.2　本章小结 224
第11章　UNREAL 226
11.1　主任务 226
11.2　像素控制任务 227
11.3　奖励值预测 229
11.4　值函数回放 230
11.5　损失函数 231
11.6　本章小结 232

扩展篇
第12章　NEAT 236
12.1　遗传算法 237
12.1.1　进化过程 237
12.1.2　算法流程 238
12.1.3　背包问题 239
12.1.4　极大（小）值问题 247
12.2　NEAT原理 255
12.2.1　基因组 255
12.2.2　变异和遗传 256
12.3　NEAT示例 258
12.4　本章小结 262
第13章　SerpentAI 263
13.1　简介 263
13.2　安装和配置 264
13.3　示例 265
13.3.1　创建Game Plugin 265
13.3.2　创建Game Agent 268
13.3.3　训练Context Classifier 271
13.3.4　训练Agent 282
13.4　本章小结 286
第14章　案例详解 287
14.1　AlphaGo 287
14.1.1　AlphaGo的前世今生 287
14.1.2　“深蓝”是谁 288
14.1.3　围棋到底有多复杂 290
14.1.4　论文要义 294
14.1.5　成绩 302
14.1.6　开源项目 303
14.2　AlphaGo Zero 304
14.2.1　改进之处 304
14.2.2　成绩 308
14.2.3　开源项目 309
14.3　试验场大观 311
14.3.1　StarCraftⅡ 311
14.3.2　VizDoom 320
14.3.3　Universe 323
14.3.4　DOTA2 324
14.4　本章小结 329
第15章　扩展讨论 331
15.1　TRPO 331
15.2　反向强化学习 332
15.3　模型压缩 333
15.3.1　剪枝 335
15.3.2　量化 336
15.3.3　结构压缩 337
15.4　本章小结 339

后记 341
附录A 342
A.1　安装Ubuntu 342
A.2　安装CUDA环境 347
A.3　安装PyTorch 348
A.4　下载本书示例代码 349
A.5　安装PyCharm 350
A.5.1　方法一 350
A.5.2　方法二 351
A.6　安装Jupyter Notebook 351
A.7　安装相关Python依赖包 352
A.7.1　安装Box2D 352
A.7.2　安装MuJoCo 352
A.7.3　安装SerpentAI 355
A.7.4　安装Spritex 359
A.7.5　安装StarCraftⅡ 360
A.7.6　安装VizDoom 363
A.8　安装OpenCV 364
A.9　Python语言简介 364
A.9.1　安装Python 365
A.9.2　Hello World 365
A.9.3　行与缩进 365
A.9.4　变量类型 366
A.9.5　循环语句 367
A.9.6　函数 368
A.9.7　模块 369
A.9.8　小结 369
A.10　本书涉及的主要开源软件版本 369
参考文献 371
```

### [白话机器学习的数学](https://item.jd.com/12685447.html)

```text
第 1章 开始二人之旅 1
1．1　对机器学习的兴趣　2
1．2　机器学习的重要性　4
1．3　机器学习的算法　7
1．4　数学与编程　12
第　2章 学习回归——基于广告费预测点击量　15
2．1　设置问题　16
2．2　定义模型　19
2．3　最小二乘法　22
2．4　多项式回归　41
2．5　多重回归　45
2．6　随机梯度下降法　52
第3章　学习分类——基于图像大小进行分类　59
3．1　设置问题　60
3．2　内积　64
3．3　感知机　69
3．3．1　训练数据的准备　71
3．3．2　权重向量的更新表达式　74
3．4　线性可分　80
3．5　逻辑回归　82
3．5．1　sigmoid函数　83
3．5．2　决策边界　86
3．6　似然函数　91
3．7　对数似然函数　96
3．8　线性不可分　104
第4章　评估——评估已建立的模型　109
4．1　模型评估　110
4．2　交叉验证　112
4．2．1　回归问题的验证　112
4．2．2　分类问题的验证　117
4．2．3　精确率和召回率　121
4．2．4　F值　125
4．3　正则化　130
4．3．1　过拟合　130
4．3．2　正则化的方法　131
4．3．3　正则化的效果　132
4．3．4　分类的正则化　139
4．3．5　包含正则化项的表达式的微分　140
4．4　学习曲线　144
4．4．1　欠拟合　144
4．4．2　区分过拟合与欠拟合　146
第5章　实现——使用Python编程　153
5．1　使用Python实现　154
5．2　回归　155
5．2．1　确认训练数据　155
5．2．2　作为一次函数实现　158
5．2．3　验证　164
5．2．4　多项式回归的实现　168
5．2．5　随机梯度下降法的实现　176
5．3　分类——感知机　179
5．3．1　确认训练数据　179
5．3．2　感知机的实现　182
5．3．3　验证　185
5．4　分类——逻辑回归　188
5．4．1　确认训练数据　188
5．4．2　逻辑回归的实现　189
5．4．3　验证　194
5．4．4　线性不可分分类的实现　197
5．4．5　随机梯度下降法的实现　204
5．5　正则化　206
5．5．1　确认训练数据　206
5．5．2　不应用正则化的实现　210
5．5．3　应用了正则化的实现　212
5．6　后话　215
附录
A．1　求和符号、求积符号　218
A．2　微分　220
A．3　偏微分　224
A．4　复合函数　227
A．5　向量和矩阵　229
A．6　几何向量　233
A．7　指数与对数　237
A．8　Python环境搭建　241
A．9　Python基础知识　244
A．10　NumPy基础知识　254
```

### [漫话人工智能：坂本真树老师带你轻松读懂人工智能](https://item.jd.com/12790787.html)
```text
第1章 人工智能是什么？
1.1 人工智能是什么时候出现的？002
● 人的智能？人工智能？003
● 图灵测试：哪个是人类？004
● 寂寞的人工智能？！006
● 人和人工智能的区别007
● 伴随着计算机发展009
● AI的历史：达特茅斯会议010
● AI的历史：第一次人工智能热潮011
● AI的历史：第二次人工智能热潮013
● 现在，第三次人工智能热潮！015
1.2 这是人工智能？016
● 人工智能与机器人的区别017
● 机器人研究？人工智能研究？019
● 人工智能需要身体吗？020
● 第1级人工智能023
● 第2级人工智能024
● 第3级人工智能026
● 第4级人工智能，专用人工智能027
● 第5级人工智能，通用人工智能028
1.3 人工智能会超越人类吗？030
● 奇点是什么？031
● 奇点：可怕？不可？032
● 如何实现通用人工智能？033
● AI导致人类灭亡的可能性有多大？034
● AI之下我们的未来会怎样改变呢？036
● 将来，哪些职业会消失？037
● 将来，哪些职业会留下来？039

第2章 容易导入人工智能的事物和不容易导入人工智能的事物
2.1 容易导入人工智能的事物042
● 可以导入网络上的任何信息043
● 0和1数字数据044
● 各种数据（语言、动画、音频）046
● 让计算机拥有视觉048
● 数码相机的演变049
● 像素提高，超过人类？！050
● 世界共享的数据051
● 图像识别的竞赛：ILSVRC052
● 让计算机拥有听觉054
● 使用两个麦克风的语音识别055
● 多个麦克风056
● 把语音转化成文字？058
● 声学模型和语言模型060
2.2 不容易导入人工智能的事物 062
●“意思”很难懂…… 063
● 什么是语义网络？ 064
● 不理解“意思”也能够做出回答？ 065
● 什么是潜在语义分析？ 067
● 为什么Torobo-kun 选择放弃 067
● 如果要变聪明，需要五感齐备吗？ 069
● 人工智能的味觉是什么？ 070
● 人工智能的嗅觉是什么？ 070
● 将来会怎么处理气味？072
● 人工智能的触觉是什么？073
● 实现触觉真的很难！074

第3章 人工智能是怎样从信息中学习的？
3.1 什么是机器学习？ 078
● 让机器设备（计算机）也能够学习！ 079
● 什么是监督学习？ 080
● 分类问题：判断垃圾邮件 082
● 回归问题：预测数值 084
● 寻找合适的线（函数）！ 085
● 当心过度学习！ 088
● 什么是无监督学习？ 090
● 试着分组吧！ 092
● k-means 分类方法 094
● 强化学习是“蜜糖”与“鞭子” 095
3.2 什么是神经网络？097
● 大脑依靠神经元运作098
● 人工神经元的构造100
● 代表了重要度和信赖度的权重102
● 赫布定律103
● 什么是感知机？104
● 线性不可分！105
● BP算法（误差反向传播算法）106
● 为了减小误差，调整权重！108
● 增加层数：信息传递不到!110
● 支持向量机的优点是什么？110
● 权衡过度学习和泛化112
3.3 深度学习有哪些厉害之处？113
● 深度学习成名的日子114
● 能够自己提取特征，厉害！115
● 4层以上的深度学习116
● 自编码的输入和输出是相同的！117
● 让输入与输出具有相同的意义118
● 或许和人越来越像？120
● 深度学习的方法120
3.4 AI三大模型中的“遗传算法”是什么？124
●AI三大模型的方方面面125
● 以达尔文的进化论为基础125
● 遗传算法的使用方法126

第4章 人工智能的应用实例
4.1 人工智能的进化在“游戏”中的应用实例130
● 游戏AI 的进化历史130
●人类与AI 对战（国际象棋篇）132
●人类与AI 对战（日本象棋篇）133
●人类与AI 对战（围棋篇）134
4.2 第三次AI热潮的导火索在“图像”领域的应用实例136
● 谷歌的猫136
● 图像识别的发展138
● 医疗领域的应用（庄野实验室）139
● 医疗领域的应用（恶性黑色素瘤的判别） 140
● 医疗领域的应用（癌症的检测）141
● 为了提高诊断的准确度142
4.3 “自动驾驶AI”的实际应用143
● 自动到什么程度？143
● 为了实现自动驾驶145
● 自动驾驶的训练步骤146
● 为了掌握位置和情况147
● 事故的原因究竟是什么？ 149
4.4 “对话AI”的应用实例150
● 为了和计算机对话150
●“有知识”对话AI152
●“无知识”对话AI154
● 制造对话的三种技术155
● 为了自然的对话156
4.5 “遗传算法”在“拟声拟态词”上的应用实例158
● 贴近人心的拟声拟态词158
● 生成拟声拟态词的系统159
● 拟声拟态词的生成160
● 在优化过程中要做些什么呢162
4.6 AI在“艺术”领域的实践164
●AI在艺术方面的挑战（小说篇）164
●AI小说项目166
●AI在艺术方面的挑战（绘画篇）168
●AI在艺术方面的挑战（作曲篇）170

结语171

参考文献174

索引176
```

### [人工智能数学基础 中国人工智能学会副理事长力荐教材](https://item.jd.com/13009168.html#none)

```text
第1 章 人工智能与数学基础..........１
1.1 什么是人工智能............................ 2
1.2 人工智能的发展 ............................ 2
1.3 人工智能的应用 ............................ 4
1.4 学习人工智能需要哪些知识 ............. 5
1.5 为什么要学习数学 ......................... 7
1.6 本书包括的数学知识 ...................... 8
第 1 篇
基础篇................................................................. 9
第 2 章 高等数学基础 ................. １0
2.1 函数.......................................... 11
2.2 极限..........................................13
2.3 无穷小与无穷大...........................17
2.4 连续性与导数..............................19
2.5 偏导数...................................... 24
2.6 方向导数................................... 27
2.7 梯度......................................... 29
2.8 综合实例—梯度下降法求函数的最小值.......................................31
2.9 高手点拨................................... 35
2.10 习题....................................... 38
第 3 章 微积分..............................39
3.1 微积分的基本思想 ....................... 40
3.2 微积分的解释..............................41
3.3 定积分...................................... 42
3.4 定积分的性质............................. 44
3.5 牛顿—莱布尼茨公式.................... 45
3.6 综合实例—Python 中常用的定积分求解方法................................... 49
3.7 高手点拨....................................51
3.8 习题 ........................................ 52
第 4 章 泰勒公式与拉格朗日乘子法..............................53
4.1 泰勒公式出发点.......................... 54
4.2 一点一世界................................ 54
4.3 阶数和阶乘的作用....................... 59
4.4 麦克劳林展开式的应用..................61
4.5 拉格朗日乘子法.......................... 63
4.6 求解拉格朗日乘子法.................... 64
4.7 综合实例—编程模拟实现 sinx 的n 阶泰勒多项式并验证结果.................. 67
4.8 高手点拨 ................................... 68
4.9 习题 ......................................... 68
第2 篇
核心篇............................................................... 69
第 5 章 将研究对象形式化—线性代数基础 ..........................70
5.1 向量..........................................71
5.2 矩阵......................................... 73
5.3 矩阵和向量的创建....................... 77
5.4 特殊的矩阵................................ 85
5.5 矩阵基本操作..............................91
5.6 转置矩阵和逆矩阵....................... 96
5.7 行列式..................................... 101
5.8 矩阵的秩..................................104
5.9 内积与正交...............................108
5.10 综合实例—线性代数在实际问题中的应用 ....................................... 114
5.11 高手点拨 ................................ 121
5.12 习题......................................126
第 6 章 从数据中提取重要信息—特征值与矩阵分解..........127
6.1 特征值与特征向量 .....................128
6.2 特征空间..................................133
6.3 特征值分解...............................133
6.4 SVD 解决的问题.......................135
6.5 奇异值分解（SVD）..................136
6.6 综合实例 1—利用 SVD 对图像进行压缩 .......................................140
6.7 综合实例 2—利用 SVD 推荐商品 .......................................143
6.8 高手点拨..................................150
6.9 习题 .......................................154
第 7 章 描述统计规律 1—概率论基础................................155
7.1 随机事件及其概率 ......................156
7.2 条件概率.................................. 161
7.3 独立性.....................................162
7.4 随机变量..................................165
7.5 二维随机变量............................173
7.6 边缘分布..................................177
7.7 综合实例—概率的应用.............180
7.8 高手点拨.................................. 181
7.9 习题........................................184
第 8 章 描述统计规律 2—随机变量与概率估计........................185
8.1 随机变量的数字特征 ..................186
8.2 大数定律和中心极限定理.............193
8.3 数理统计基本概念......................199
8.4 最大似然估计........................... 203
8.5 最大后验估计........................... 206
8.6 综合实例 1—贝叶斯用户满意度预测 ...................................... 209
8.7 综合实例 2—最大似然法求解模型参数 .......................................217
8.8 高手点拨 ................................ 222
8.9 习题 ....................................... 224
第 3 篇
提高篇............................................................. 225
第 9 章 随机变量的几种分布...... 226
9.1 正态分布 ................................ 227
9.2 二项分布................................. 240
9.3 泊松分布................................. 250
9.4 均匀分布..................................261
9.5 卡方分布................................. 266
9.6 Beta 分布 .............................. 273
9.7 综合实例—估算棒球运动员的击中率 ...................................... 283
9.8 高手点拨 ................................ 285
9.9 习题 ...................................... 286
第 10 章 数据的空间变换—核函数变换............................. 287
10.1 相关知识简介 ......................... 288
10.2 核函数的引入 ......................... 290
10.3 核函数实例............................ 290
10.4 常用核函数.............................291
10.5 核函数的选择......................... 294
10.6 SVM 原理 ............................ 295
10.7 非线性 SVM 与核函数的引入.... 305
10.8 综合实例—利用 SVM 构建分类
问题......................................310
10.9 高手点拨................................315
10.10 习题 ................................... 322
第 11 章 熵与激活函数 .............. 323
11.1 熵和信息熵............................ 324
11.2 激活函数 ............................... 328
11.3 综合案例—分类算法中信息熵的应用...................................... 339
11.4 高手点拨 ................................341
11.5 习题 ..................................... 342
第4 篇
应用篇............................................................. 333
第 12 章 假设检验 ..................... 344
12.1 假设检验的基本概念................. 345
12.2 Z 检验 ...................................351
12.3 t 检验 ................................... 353
12.4 卡方检验............................... 358
12.5 假设检验中的两类错误 ..............361
12.6 综合实例 1—体检数据中的假设检验问题..................................... 363
12.7 综合实例 2—种族对求职是否有影响..................................... 369
12.8 高手点拨............................... 372
12.9 习题..................................... 374
13 章 相关分析...................... 375
13.1 相关分析概述.......................... 376
13.2 皮尔森相关系数....................... 378
13.3 相关系数的计算与假设检验........ 379
13.4 斯皮尔曼等级相关.................... 385
13.5 肯德尔系数............................. 392
13.6 质量相关分析.......................... 396
13.7 品质相关分析.......................... 400
13.8 偏相关与复相关....................... 403
13.9 综合实例—相关系数计算........ 405
13.10 高手点拨.............................. 407
13.11 习题..................................... 408
第 14 章 回归分析......................409
14.1 回归分析概述...........................410
14.2 回归方程推导及应用..................412
14.3 回归直线拟合优度.....................416
14.4 线性回归的模型检验..................417
14.5 利用回归直线进行估计和预测......419
14.6 多元与曲线回归问题..................421
14.7 Python 工具包....................... 426
14.8 综合实例—个人医疗保费预测任务...................................... 432
14.9 高手点拨................................ 444
14.10 习题..................................... 446
第 15 章 方差分析......................449
15.1 方差分析概述.......................... 448
15.2 方差的比较............................. 450
15.3 方差分析.................................451
15.4 综合实例—连锁餐饮用户评级分析...................................... 460
15.5 高手点拨................................ 464
15.6 习题...................................... 466
第 16 章 聚类分析......................469
16.1 聚类分析概述.......................... 468
16.2 层次聚类................................ 470
16.3 K-Means 聚类...................... 484
16.4 DBSCAN 聚类....................... 494
16.5 综合实例—聚类分析.............. 499
16.6 高手点拨.................................512
16.7 习题.......................................512
第 17 章 贝叶斯分析....................513
17.1 贝叶斯分析概述........................514
17.2 MCMC 概述.......................... 520
17.3 MCMC 采样 ......................... 525
17.4 Gibbs 采样........................... 529
17.5 综合实例—利用 PyMC3 实现随机模拟样本分布......................... 532
17.6 高手点拨............................... 539
17.7 习题..................................... 540
```

### [零基础学机器学习](https://item.jd.com/12763913.html#none)

```text
引子：AI 菜鸟的挑战—100 天上线智能预警系统
第1 课 机器学习快速上手路径—唯有实战
1．1 机器学习的家族谱
1．1．1 新手入门机器学习的3 个好消息
1．1．2 机器学习就是从数据中发现规律
1．1．3 机器学习的类别—监督学习及其他
1．1．4 机器学习的重要分支—深度学习
1．1．5 机器学习新热点—强化学习
1．1．6 机器学习的两大应用场景—回归与分类
1．1．7 机器学习的其他应用场景
1．2 快捷的云实战学习模式
1．2．1 在线学习平台上的机器学习课程
1．2．2 用Jupyter Notebook 直接实战
1．2．3 用Google Colab 开发第一个机器学习程序
1．2．4 在Kaggle 上参与机器学习竞赛
1．2．5 在本机上“玩”机器学习
1．3 基本机器学习术语
1．3．1 特征
1．3．2 标签
1．3．3 模型
1．4 Python 和机器学习框架
1．4．1 为什么选择用Python
1．4．2 机器学习和深度学习框架
1．5 机器学习项目实战架构
1．5．1 第1 个环节：问题定义
1．5．2 第2 个环节：数据的收集和预处理
1．5．3 第3 个环节：选择机器学习模型
1．5．4 第4 个环节：训练机器，确定参数
1．5．5 第5 个环节：超参数调试和性能优化
1．6 本课内容小结
1．7 课后练习
第2 课 数学和Python 基础知识—一天搞定
2．1 函数描述了事物间的关系
2．1．1 什么是函数
2．1．2 机器学习中的函数
2．2 捕捉函数的变化趋势
2．2．1 连续性是求导的前提条件
2．2．2 通过求导发现y 如何随x 而变
2．2．3 凸函数有一个全局最低点
2．3 梯度下降是机器学习的动力之源
2．3．1 什么是梯度
2．3．2 梯度下降：下山的隐喻
2．3．3 梯度下降有什么用
2．4 机器学习的数据结构—张量
2．4．1 张量的轴、阶和形状
2．4．2 标量—0D（阶）张量
2．4．3 向量—1D（阶）张量
2．4．4 矩阵—2D（阶）张量
2．4．5 序列数据 —3D（阶）张量
2．4．6 图像数据 —4D（阶）张量
2．4．7 视频数据—5D（阶）张量
2．4．8 数据的维度和空间的维度
2．5 Python 的张量运算
2．5．1 机器学习中张量的创建
2．5．2 通过索引和切片访问张量中的数据
2．5．3 张量的整体操作和逐元素运算
2．5．4 张量的变形和转置
2．5．5 Python 中的广播
2．5．6 向量和矩阵的点积运算
2．6 机器学习的几何意义
2．6．1 机器学习的向量空间
2．6．2 深度学习和数据流形
2．7 概率与统计研究了随机事件的规律
2．7．1 什么是概率
2．7．2 正态分布
2．7．3 标准差和方差
2．8 本课内容小结
2．9 课后练习
第3 课 线性回归—预测网店的销售额
3．1 问题定义：小冰的网店广告该如何投放
3．2 数据的收集和预处理
3．2．1 收集网店销售额数据
3．2．2 数据读取和可视化
3．2．3 数据的相关分析
3．2．4 数据的散点图
3．2．5 数据集清洗和规范化
3．2．6 拆分数据集为训练集和测试集
3．2．7 把数据归一化
3．3 选择机器学习模型
3．3．1 确定线性回归模型
3．3．2 假设（预测）函数—h （x ）
3．3．3 损失（误差）函数—L （w ，b ）
3．4 通过梯度下降找到最佳参数
3．4．1 训练机器要有正确的方向
3．4．2 凸函数确保有最小损失点
3．4．3 梯度下降的实现
3．4．4 学习速率也很重要
3．5 实现一元线性回归模型并调试超参数
3．5．1 权重和偏置的初始值
3．5．2 进行梯度下降
3．5．3 调试学习速率
3．5．4 调试迭代次数
3．5．5 在测试集上进行预测
3．5．6 用轮廓图描绘L 、w 和b 的关系
3．6 实现多元线性回归模型
3．6．1 向量化的点积运算
3．6．2 多变量的损失函数和梯度下降
3．6．3 构建一个线性回归函数模型
3．6．4 初始化权重并训练机器
3．7 本课内容小结
3．8 课后练习
第4 课 逻辑回归—给病患和鸢尾花分类
4．1 问题定义：判断客户是否患病
4．2 从回归问题到分类问题
4．2．1 机器学习中的分类问题
4．2．2 用线性回归+ 阶跃函数完成分类
4．2．3 通过Sigmiod 函数进行转换
4．2．4 逻辑回归的假设函数
4．2．5 逻辑回归的损失函数
4．2．6 逻辑回归的梯度下降
4．3 通过逻辑回归解决二元分类问题
4．3．1 数据的准备与分析
4．3．2 建立逻辑回归模型
4．3．3 开始训练机器
4．3．4 测试分类结果
4．3．5 绘制损失曲线
4．3．6 直接调用Sklearn 库
4．3．7 哑特征的使用
4．4 问题定义：确定鸢尾花的种类
4．5 从二元分类到多元分类
4．5．1 以一对多
4．5．2 多元分类的损失函数
4．6 正则化、欠拟合和过拟合
4．6．1 正则化
4．6．2 欠拟合和过拟合
4．6．3 正则化参数
4．7 通过逻辑回归解决多元分类问题
4．7．1 数据的准备与分析
4．7．2 通过Sklearn 实现逻辑回归的多元分类
4．7．3 正则化参数—C 值的选择
4．8 本课内容小结
4．9 课后练习
第5 课 深度神经网络—找出可能流失的客户
5．1 问题定义：咖哥接手的金融项目
5．2 神经网络的原理
5．2．1 神经网络极简史
5．2．2 传统机器学习算法的局限性
5．2．3 神经网络的优势
5．3 从感知器到单隐层网络
5．3．1 感知器是最基本的神经元
5．3．2 假设空间要能覆盖特征空间
5．3．3 单神经元特征空间的局限性
5．3．4 分层：加入一个网络隐层
5．4 用Keras 单隐层网络预测客户流失率
5．4．1 数据的准备与分析
5．4．2 先尝试逻辑回归算法
5．4．3 单隐层神经网络的Keras 实现
5．4．4 训练单隐层神经网络
5．4．5 训练过程的图形化显示
5．5 分类数据不平衡问题：只看准确率够用吗
5．5．1 混淆矩阵、精确率、召回率和F1 分数
5．5．2 使用分类报告和混淆矩阵
5．5．3 特征缩放的魔力
5．5．4 阈值调整、欠采样和过采样
5．6 从单隐层神经网络到深度神经网络
5．6．1 梯度下降：正向传播和反向传播
5．6．2 深度神经网络中的一些可调超参数
5．6．3 梯度下降优化器
5．6．4 激活函数：从Sigmoid 到ReLU
5．6．5 损失函数的选择
5．6．6 评估指标的选择
5．7 用Keras 深度神经网络预测客户流失率
5．7．1 构建深度神经网络
5．7．2 换一换优化器试试
5．7．3 神经网络正则化：添加Dropout 层
5．8 深度神经网络的调试及性能优化
5．8．1 使用回调功能
5．8．2 使用TensorBoard
5．8．3 神经网络中的过拟合
5．8．4 梯度消失和梯度爆炸
5．9 本课内容小结
5．10 课后练习
第6课 卷积神经网络—识别狗狗的图像
6．1 问题定义：有趣的狗狗图像识别
6．2 卷积网络的结构
6．3 卷积层的原理
6．3．1 机器通过“模式”进行图像识别
6．3．2 平移不变的模式识别
6．3．3 用滑动窗口抽取局部特征
6．3．4 过滤器和响应通道
6．3．5 对特征图进行卷积运算
6．3．6 模式层级结构的形成
6．3．7 卷积过程中的填充和步幅
6．4 池化层的功能
6．5 用卷积网络给狗狗图像分类
6．5．1 图像数据的读入
6．5．2 构建简单的卷积网络
6．5．3 训练网络并显示误差和准确率
6．6 卷积网络性能优化
6．6．1 第一招：更新优化器并设置学习速率
6．6．2 第二招：添加Dropout 层
6．6．3 “大杀器”：进行数据增强
6．7 卷积网络中特征通道的可视化
6．8 各种大型卷积网络模型
6．8．1 经典的VGGNet
6．8．2 采用Inception 结构的GoogLeNet
6．8．3 残差网络ResNet
6．9 本课内容小结
6．10 课后练习
第7 课 循环神经网络—鉴定留言及探索系外行星
7．1 问题定义：鉴定评论文本的情感属性
7．2 循环神经网络的原理和结构
7．2．1 什么是序列数据
7．2．2 前馈神经网络处理序列数据的局限性
7．2．3 循环神经网络处理序列问题的策略
7．2．4 循环神经网络的结构
7．3 原始文本如何转化成向量数据
7．3．1 文本的向量化：分词
7．3．2 通过One-hot 编码分词
7．3．3 词嵌入
7．4 用SimpleRNN 鉴定评论文本
7．4．1 用Tokenizer 给文本分词
7．4．2 构建包含词嵌入的SimpleRNN
7．4．3 训练网络并查看验证准确率
7．5 从SimpleRNN 到LSTM
7．5．1 SimpleRNN 的局限性
7．5．2 LSTM 网络的记忆传送带
7．6 用LSTM 鉴定评论文本
7．7 问题定义：太阳系外哪些恒星有行星环绕
7．8 用循环神经网络处理时序问题
7．8．1 时序数据的导入与处理
7．8．2 建模：CNN 和RNN 的组合
7．8．3 输出阈值的调整
7．8．4 使用函数式API
7．9 本课内容小结
7．10 课后练习
第8 课 经典算法“宝刀未老”
8．1 K 最近邻
8．2 支持向量机
8．3 朴素贝叶斯
8．4 决策树
8．4．1 熵和特征节点的选择
8．4．2 决策树的深度和剪枝
8．5 随机森林
8．6 如何选择最佳机器学习算法
8．7 用网格搜索超参数调优
8．8 本课内容小结
8．9 课后练习
第9 课 集成学习“笑傲江湖”
9．1 偏差和方差—机器学习性能优化的风向标
9．1．1 目标：降低偏差与方差
9．1．2 数据集大小对偏差和方差的影响
9．1．3 预测空间的变化带来偏差和方差的变化
9．2 Bagging 算法—多个基模型的聚合
9．2．1 决策树的聚合
9．2．2 从树的聚合到随机森林
9．2．3 从随机森林到极端随机森林
9．2．4 比较决策树、树的聚合、随机森林、极端随机森林的效率
9．3 Boosting 算法—锻炼弱模型的“肌肉”
9．3．1 AdaBoost 算法
9．3．2 梯度提升算法
9．3．3 XGBoost 算法
9．3．4 Bagging 算法与Boosting 算法的不同之处
9．4 Stacking/Blending 算法—以预测结果作为新特征
9．4．1 Stacking 算法
9．4．2 Blending 算法
9．5 Voting/Averaging 算法—集成基模型的预测结果
9．5．1 通过Voting 进行不同算法的集成
9．5．2 通过Averaging 集成不同算法的结果
9．6 本课内容小结
9．7 课后练习
第10 课 监督学习之外—其他类型的机器学习
10．1 无监督学习—聚类
10．1．1 K 均值算法
10．1．2 K 值的选取：手肘法
10．1．3 用聚类辅助理解营销数据
10．2 无监督学习—降维
10．2．1 PCA 算法
10．2．2 通过PCA 算法进行图像特征采样
10．3 半监督学习
10．3．1 自我训练
10．3．2 合作训练
10．3．3 半监督聚类
10．4 自监督学习
10．4．1 潜隐空间
10．4．2 自编码器
10．4．3 变分自编码器
10．5 生成式学习
10．5．1 机器学习的生成式
10．5．2 生成式对抗网络
10．6 本课内容小结
10．7 课后练习
第11 课 强化学习实战—咖哥的冰湖挑战
11．1 问题定义：帮助智能体完成冰湖挑战
11．2 强化学习基础知识
11．2．1 延迟满足
11．2．2 更复杂的环境
11．2．3 强化学习中的元素
11．2．4 智能体的视角
11．3 强化学习基础算法Q-Learning 详解
11．3．1 迷宫游戏的示例
11．3．2 强化学习中的局部最优
11．3．3 ε -Greedy 策略
11．3．4 Q-Learning 算法的伪代码
11．4 用Q-Learning 算法来解决冰湖挑战问题
11．4．1 环境的初始化
11．4．2 Q-Learning 算法的实现
11．4．3 Q-Table 的更新过程
11．5 从Q-Learning 算法到SARSA算法
11．5．1 异策略和同策略
11．5．2 SARSA 算法的实现
11．6 用SARSA 算法来解决冰湖挑战问题
11．7 Deep Q Network 算法：用深度网络实现Q-Learning
11．8 本课内容小结
11．9 课后练习
尾声：如何实现机器学习中的知识迁移及持续性的学习
练习答案
```

### [机器学习算法的数学解析与Python实现 零基础入门通俗易懂 [The First Book of Machine Learning]](https://item.jd.com/12615709.html#none)
```text
前言

第1章　机器学习概述 1

1.1　什么是机器学习 1

1.2　机器学习的几个需求层次 3

1.3　机器学习的基本原理 5

1.4　机器学习的基本概念 7

1.4.1　书中用到的术语介绍 7

1.4.2　机器学习的基本模式 11

1.4.3　优化方法 12

1.5　机器学习问题分类 14

1.6　常用的机器学习算法 15

1.7　机器学习算法的性能衡量指标 16

1.8　数据对算法结果的影响 18

第2章　机器学习所需的环境 20

2.1　常用环境 20

2.2　Python简介 21

2.2.1　Python的安装 23

2.2.2　Python的基本用法 24

2.3　Numpy简介 25

2.3.1　Numpy的安装 26

2.3.2　Numpy的基本用法 26

2.4　Scikit-Learn简介 27

2.4.1　Scikit-Learn的安装 28

2.4.2　Scikit-Learn的基本用法 28

2.5　Pandas简介 29

2.5.1　Pandas的安装 30

2.5.2　Pandas的基本用法 31

第3章　线性回归算法 33

3.1　线性回归：“钢铁直男”解决回归问题的正确方法 33

3.1.1　用于预测未来的回归问题 35

3.1.2　怎样预测未来 38

3.1.3　线性方程的“直男”本性 40

3.1.4　最简单的回归问题—线性回归问题 44

3.2　线性回归的算法原理 46

3.2.1　线性回归算法的基本思路 46

3.2.2　线性回归算法的数学解析 48

3.2.3　线性回归算法的具体步骤 53

3.3　在Python中使用线性回归算法 54

3.4　线性回归算法的使用场景 60

第4章　Logistic回归分类算法 61

4.1　Logistic回归：换上“S型曲线马甲”的线性回归 61

4.1.1　分类问题：选择困难症患者的自我救赎 63

4.1.2　Logistic函数介绍 66

4.1.3　此回归非彼回归：“LR”辨析 70

4.2　Logistic回归的算法原理 71

4.2.1　Logistic回归算法的基本思路 71

4.2.2　Logistic回归算法的数学解析 74

4.2.3　Logistic回归算法的具体步骤 78

4.3　在Python中使用Logistic回归算法 78

4.4　Logistic回归算法的使用场景 81

第5章　KNN分类算法 82

5.1　KNN分类算法：用多数表决进行分类 82

5.1.1　用“同类相吸”的办法解决分类问题 84

5.1.2　KNN分类算法的基本方法：多数表决 86

5.1.3　表决权问题 89

5.1.4　KNN的具体含义 89

5.2　KNN分类的算法原理 90

5.2.1　KNN分类算法的基本思路 90

5.2.2　KNN分类算法的数学解析 93

5.2.3　KNN分类算法的具体步骤 94

5.3　在Python中使用KNN分类算法 95

5.4　KNN分类算法的使用场景 96

第6章　朴素贝叶斯分类算法 98

6.1　朴素贝叶斯：用骰子选择 98

6.1.1　从统计角度看分类问题 99

6.1.2　贝叶斯公式的基本思想 102

6.1.3　用贝叶斯公式进行选择 104

6.2　朴素贝叶斯分类的算法原理 106

6.2.1　朴素贝叶斯分类算法的基本思路 106

6.2.2　朴素贝叶斯分类算法的数学解析 108

6.2.3　朴素贝叶斯分类算法的具体步骤 111

6.3　在Python中使用朴素贝叶斯分类算法 111

6.4　朴素贝叶斯分类算法的使用场景 112

第7章　决策树分类算法 114

7.1　决策树分类：用“老朋友”if-else进行选择 114

7.1.1　程序员的选择观：if-else 116

7.1.2　如何种植一棵有灵魂的“树” 118

7.1.3　决策条件的选择艺术 119

7.1.4　决策树的剪枝问题 122

7.2　决策树分类的算法原理 125

7.2.1　决策树分类算法的基本思路 125

7.2.2　决策树分类算法的数学解析 127

7.2.3　决策树分类算法的具体步骤 133

7.3　在Python中使用决策树分类算法 134

7.4　决策树分类算法的使用场景 135

第8章　支持向量机分类算法 137

8.1　支持向量机：线性分类器的“王者” 137

8.1.1　距离是不同类别的天然间隔 139

8.1.2　何为“支持向量” 140

8.1.3　从更高维度看“线性不可分” 142

8.2　支持向量机分类的算法原理 146

8.2.1　支持向量机分类算法的基本思路 146

8.2.2　支持向量机分类算法的数学解析 150

8.2.3　支持向量机分类算法的具体步骤 153

8.3　在Python中使用支持向量机分类算法 154

8.4　支持向量机分类算法的使用场景 156

第9章　K-means聚类算法 157

9.1　用投票表决实现“物以类聚” 157

9.1.1　聚类问题就是“物以类聚”的实施问题 159

9.1.2　用“K”来决定归属类别 162

9.1.3　度量“相似”的距离 164

9.1.4　聚类问题中的多数表决 165

9.2　K-means聚类的算法原理 168

9.2.1　K-means聚类算法的基本思路 168

9.2.2　K-means聚类算法的数学解析 169

9.2.3　K-means聚类算法的具体步骤 170

9.3　在Python中使用K-means聚类算法 171

9.4　K-means聚类算法的使用场景 172

第10章　神经网络分类算法 174

10.1　用神经网络解决分类问题 174

10.1.1　神经元的“内心世界” 177

10.1.2　从神经元看分类问题 180

10.1.3　神经网络的“细胞”：人工神经元 181

10.1.4　构成网络的魔力 184

10.1.5　神经网络与深度学习 188

10.2　神经网络分类的算法原理 188

10.2.1　神经网络分类算法的基本思路 188

10.2.2　神经网络分类算法的数学解析 190

10.2.3　神经网络分类算法的具体步骤 193

10.3　在Python中使用神经网络分类算法 194

10.4　神经网络分类算法的使用场景 195

第11章　集成学习方法 197

11.1　集成学习方法：三个臭皮匠赛过诸葛亮 197

11.1.1　集成学习方法与经典机器学习算法的关系 198

11.1.2　集成学习的主要思想 199

11.1.3　几种集成结构 200

11.2　集成学习方法的具体实现方式 202

11.2.1　Bagging算法 202

11.2.2　Boosting算法 202

11.2.3　Stacking算法 202

11.3　在Python中使用集成学习方法 203

11.4　集成学习方法的使用场景 205
```

### [管理者终身学习：白话统计学（第3版）](https://item.jd.com/11398553.html)

```text
第1章 导论：社会科学研究的原理和术语
总体和样本，统计量和参数
抽样问题
变量类型和测量尺度
研究设计
分布和图表的重要性
总结与展望
第1章 的术语表

第2章 中心趋势的测度
中心趋势测度详解
例子：偏态分布的均值、中位数和众数
行文表述
总结与展望
第2章 的术语和符号表

第3章 变异程度的测度
变异程度测度详解
例子：考察极差、方差和标准差
总结与展望
第3章 的术语和符号表

第4章 正态分布
正态分布详解
例子：非正态分布中应用正态分布概率
总结与展望
第4章 的术语表

第5章 标准化与z分数
标准化与z分数详解
例子：比较原始取值和z分数
总结与展望
第5章 的术语和符号表

第6章 标准误
标准误详解
例子：样本容量和标准差对标准误的影响
总结与展望
第6章 的术语和符号表

第7章 统计显著性、效应量和置信区间
统计显著性详解
效应量详解
置信区间详解
例子：关于动机的单样本t检验——统计显著性、置信区间和效应量
总结与展望
第7章 的术语和符号表
推荐读物

第8章 相关性
皮尔逊相关系数详解
其他类型相关系数概述
例子：评级和考试分数之间的相关性
行文表述
总结与展望
第8章 的术语与符号表
推荐读物

第9章 t检验
独立样本t检验详解
配对或相依样本t检验详解
例子：比较男女生的学分绩点
例子：比较五年级与六年级的学分绩点
行文表述
总结与展望
第9章 的术语和符号表

第10章 单因子方差分析
单因子方差分析详解
例子：5岁、8岁和12岁孩子的偏好比较
行文表述
总结与展望
第10章 的术语和符号表
推荐读物

第11章 因子方差分析
因子方差分析详解
例子：表现、选择以及公开或私密评价
行文表述
总结与展望
第11章 的术语表
推荐读物

第12章 复测方差分析
复测方差分析详解
例子：关于标准化测试的态度改变
行文表述
总结与展望
第12章 的术语及符号表
推荐读物

第13章 回归
回归详解
多元回归
例子：预测自我妨碍策略的使用
行文表述
总结与展望
第13章 的术语与符号表
推荐读物

第14章 卡方独立性检验
卡方独立性检验详解
例子：世代状态与成绩水平
行文表述
总结与展望
第14章 术语及符号表

第15章 因子分析与信度分析：数据整理技术
因子分析详解
探索性因子分析：一个更具体的例子
信度分析详解
行文表述
总结
第15章 的术语和符号表
推荐读物

附录A 正态分布曲线下Z两侧的面积
附录B t分布的临界值
附录C F分布的临界值
附录D 学生化极差统计量的临界值（用于Tukey HSD检验）
附录E 卡方分布的临界值
参考文献
符号表
译后记

```

### [白话统计(博文视点出品)](https://item.jd.com/12310800.html)
```text
第 1 篇 基础篇
第1 章 为什么要学统计 2
1．1 统计学有什么用 3
1．2 生活世事皆统计 4
1．3 如何学统计 4

第 2 章 变异――统计学存在的基础 6
2．1 随机与变异 6
2．2 特朗普与罗斯福的胜出――抽样调查到底可不可靠 8
2．3 什么是抽样误差 9

第 3 章 郭靖的内力能支撑多久――谈概率分布 11
3．1 累积分布与概率密度的通俗理解 12
3．2 是生存还是死亡？这是一个问题――用Weibull 分布寻找生存规律 16
3．3 2003 年的那场SARS――用Logistic 分布探索疾病流行规律 20
3．4 “普通”的正态分布 23
3．5 几个常用分布――t 分布、χ2 分布、F 分布 28

第 4 章 关于统计资料类型的思考 35
4．1 计数资料等于分类资料吗 36
4．2 计数资料可否采用连续资料的方法进行分析 37
4．3 分类资料中的无序和有序是如何确定的 38
4．4 连续资料什么时候需要转换为分类资料 39
4．5 连续资料如何分组――寻找cut-off 值的多种方法 41
4．6 什么是虚拟变量/哑变量 47

第 5 章 如何正确展示你的数据 52
5．1 均数和中位数――你被平均了吗 53
5．2 方差与标准差――变异的度量 54
5．3 自由度――你有多少自由活动的范围 56
5．4 百分位数――利用百分数度量相对位置 57
5．5 如何比较苹果和橘子――利用Z 值度量相对位置 59
5．6 某百岁老人调查报告说：少运动才能活得久――谈一下比例和率 61
5．7 在文章中如何正确展示百分比 63

第 6 章 寻找失踪的运动员――中心极限定理 64
6．1 中心极限定理针对的是样本统计量而非原始数据 65
6．2 样本量大于30 就可以认为是正态分布了吗 67

第 7 章 从“女士品茶”中领会假设检验的思想 70
7．1 女士品茶的故事 70
7．2 零假设和备择假设 ． 72
7．3 假设检验中的两类错误 73
7．4 P 值的含义 76
7．5 为什么P 值小于0．05（而不是0．02）才算有统计学意义 78
7．6 为什么零假设要设定两组相等而不是两组不等 79

第 8 章 参数估计――一叶落而知秋 81
8．1 点估计 81
8．2 最小二乘估计 82
8．3 最大似然估计 84
8．4 贝叶斯估计 86

第 9 章 置信区间估计――给估计留点余地 88
9．1 置信区间的理论与实际含义 88
9．2 置信区间与P 值的关系 90
9．3 利用标准误计算置信区间 91
9．4 利用Bootstrap 法估计置信区间 92

第 2 篇 实用篇
第10 章 常用统计方法大串讲 98
10．1 一般线性模型――方差分析与线性回归的统一 99
10．2 广义线性模型――线性回归与Logistic 回归的统一 103
10．3 广义可加模型――脱离“线性”束缚 107
10．4 多水平模型――打破“独立”条件 112
10．5 结构方程模型――从单因单果到多因多果 119

第 11 章 正态性与方差齐性 127
11．1 用统计检验方法判断正态性 127
11．2 用描述的方法判断正态性 130
11．3 方差分析中的方差齐性判断 133
11．4 理解线性回归中的方差齐性 135

第 12 章 t 检验――不仅是两组比较 138
12．1 从另一个角度来理解t 检验 138
12．2 如何正确应用t 检验 140
12．3 t 检验用于回归系数的检验 141
12．4 t 检验的替代――Wilcoxon 秩和检验 142

第 13 章 方差分析与变异分解 145
13．1 方差分析中变异分解的思想 145
13．2 为什么回归分析中也有方差分析 147
13．3 铁打的方差分析，流水的实验设计 148
13．4 方差分析后为什么要进行两两比较 152
13．5 多重比较方法的选择建议 154
13．6 所有的多组都需要做两两比较吗――兼谈固定效应和随机效应 164
13．7 重复测量方差分析详解 166
13．8 方差分析的替代――Kruskal-Wallis 秩和检验 176
13．9 多组秩和检验后的两两比较方法 178

第 14 章 卡方检验――有“卡”未必走遍天下 181
14．1 卡方检验用于分类资料组间比较的思想 181
14．2 卡方用于拟合优度评价――从Hardy-Weinberg 定律谈起 184
14．3 似然比χ2、M-H χ2、校正χ2 与Fisher 精确检验 186
14．4 等级资料到底可不可以用卡方检验 191
14．5 卡方检验的两两比较 193
14．6 Cochran-Armitage 趋势检验 194
14．7 分类变量的赋值是如何影响分析结果的 196

第 15 章 相关分析与一致性检验 200
15．1 从协方差到线性相关系数 200
15．2 线性相关系数及其置信区间 203
15．3 如何比较两个线性相关系数有无差异 206
15．4 分类资料的相关系数 207
15．5 基于秩次的相关系数 210
15．6 相关分析中的几个陷阱 213
15．7 用ICC 和CCC 指标判断一致性 215
15．8 用Bland-Altman 图判断一致性 218
15．9 Kappa 检验在一致性分析中的应用 219

第 16 章 线性回归及其分析思路 222
16．1 残差――识别回归模型好坏的关键 223
16．2 回归系数的正确理解 226
16．3 回归系数检验VS 模型检验 227
16．4 均值的置信区间VS 个体的预测区间 228
16．5 逐步回归筛选变量到底可不可靠――谈变量筛选策略 230
16．6 如何评价模型是好还是坏――交叉验证思路 237
16．7 线性回归的应用条件――你的数据能用线性回归吗 240
16．8 如何处理非正态――Box-Cox 变换 247
16．9 如何处理非线性――Box-Tidwell 变换 248
16．10 方差不齐怎么办――加权最小二乘法 250
16．11 当共线性导致结果异常时怎么办――岭回归、Lasso 回归 254
16．12 发现异常值应该删除吗――谈几种处理异常值的方法 260
16．13 如何处理缺失值――是删除还是填补 268
16．14 一个非教材的非典型案例――线性回归的综合分析 276
```

### [程序员的AI书：从代码开始]https://e.jd.com/30606707.html?ebook=1)

```text
版权信息
内容简介
推荐序一
推荐序二
推荐序三
上篇
第1章 机器学习的Hello World
1.1 机器学习简介
1.2 机器学习应用的核心开发流程
1.3 从代码开始
1.4 本章小结
1.5 本章参考文献
第2章 手工实现神经网络
2.1 感知器
2.2 线性回归、梯度下降及实现
2.3 随机梯度下降及实现
2.4 单层神经网络的Python实现
2.5 本章小结
2.6 本章参考文献
第3章 上手Keras
3.1 Keras简介
3.2 Keras开发入门
3.3 Keras的概念说明
3.4 再次代码实战
3.5 本章小结
3.6 本章参考文献
第4章 预测与分类：简单的机器学习应用
4.1 机器学习框架之sklearn简介
4.2 初识分类算法
4.3 决策树
4.4 线性回归
4.5 逻辑回归
4.6 神经网络
4.7 本章小结
4.8 本章参考文献
下篇
第5章 推荐系统基础
5.1 推荐系统简介
5.2 相似度计算
5.3 协同过滤
5.4 LR模型在推荐场景下的应用
5.5 多模型融合推荐模型：Wide＆Deep模型
5.6 本章小结
5.7 本章参考文献
第6章 项目实战：聊天机器人
6.1 聊天机器人的发展历史
6.2 循环神经网络
6.3 Seq2Seq原理介绍及实现
6.4 Attention
6.5 本章小结
6.6 本章参考文献
第7章 图像分类实战
7.1 图像分类与卷积神经网络
7.2 卷积神经网络的工作原理
7.3 案例实战：交通图标分类
7.4 优化策略
7.5 本章小结
7.6 本章参考文献
第8章 目标识别
8.1 CNN的演化
8.2 YOLO
8.3 YOLO v3的具体实现
8.4 本章小结
8.5 本章参考文献
第9章 模型部署与服务
9.1 生产环境中的模型服务
9.2 TensorFlow Serving的应用
9.3 本章小结
9.4 本章参考文献
```

### [程序员数学从零开始](https://item.jd.com/12710583.html)

```text
第1章重新认识整数（整数分解）

1.1学生的代码和老师的代码2
1.2整除和余数3
1.3素数5
1.4整数分解8
1.5最大公约数11
1.6青蛙约会16
1.7最小公倍数20
1.8哥德巴赫猜想猜的是什么?22
1.9整数比自然数更多吗？23
1.10全体实数比±1之间的实数更多吗？23
1.11大整数的乘法24
1.12小结29

第2章密码疑云（数论）

2.1密码简史31
2.2被窃听与被冒充33
2.3密码体制34
2.4数字签名38
2.5数字证书40
2.6RSA体制40
2.7攻破心的壁垒49
2.8来自量子计算的挑战50
2.9小结51

第3章递归的逻辑（计数）

3.1递归关系式54
3.2不断繁殖的兔子——递归关系模型54
3.3递归关系的基本解法57
3.4递归算法61
3.5动态编程62
3.6递归与分治64
3.7打印一棵二叉树69
3.8分形之美73
3.9米诺斯的迷宫78
3.10小结87

第4章O和大Θ（算法复杂度）

4.1算法分析89
4.2运行比较法91
4.3数学分析法91
4.4大O 96
4.5大Θ101
4.6二分查找有多快？103
4.7跨床大桥能完成吗？105
4.8冒泡排序真的慢吗？108
4.9小结112

第5章搜索的策略（搜索算法）

5.1盲目搜索114
5.2八皇后问题115
5.3贪心策略122
5.4小偷的背包122
5.5骑士旅行126
5.6觐天宝匣上的拼图134
5.7小结142

第6章最短路径（A搜索）

6.1A搜索144
6.2通往基地的捷径147
6.3再战觐天宝匣162
6.4小结170

第7章退而求其次（遗传算法）

7.1小偷又来了172
7.2遗传算法172
7.3椭圆中的最大矩形184
7.4宿管员的烦恼189
7.5小结211

第8章网络流（图论）

8.1基本概念和术语213
8.2寻找最大流218
8.3补给线上的攻防战227
8.4姜子牙的粮道232
8.5缓解拥堵的高速公路234
8.6皇家飞行员的匹配236
8.7小结239

第9章拟合的策略（最小二乘法）

9.1问题的源头241
9.2最小二乘法242
9.3线性回归249
9.4非线性问题252
9.5中国人口总量的线性拟合260
9.6正态分布的拟合曲线264
9.7小结267

第10章异常检测（半监督学习和无监督学习）

10.1监督学习不灵了269
10.2基于一元正态分布的异常检测270
10.3基于多元正态分布的异常检测276
10.4局部异常因子算法285
10.5小结295

第11章浅谈P/NP问题（非确定性问题）

11.1水浒英雄卡的故事297
11.2这些奇怪的名字298
11.3如何面对NP问题301
11.4如果P=NP305
11.5小结306

附录

A同余和模运算307
B切割图片的代码308
C拉格朗日乘子法310
D多元线性回归的推导过程311
E多元函数的泰勒展开314
F最大似然原理315
```


### [程序员的数学思维修炼（趣味解读）](https://item.jd.com/11434283.html)

```text
第1章 数据的表示
1.1 一则童话
1.1.1 0和1的故事
1.1.2 0是什么都没有？
1.1.3 0的位置
1.1.4 程序中的
1.2 司空见惯的十进制数
1.2.1 远古的结绳记事
1.2.2 什么是十进制计数
1.2.3 为啥人类习惯十进制
1.2.4 十进制运算规则
1.2.5 十进制数的分解
1.2.6 20！等于多少
1.2.7 大整数构想
1.3 为啥要用二进制
1.3.1 人脑与电脑
1.3.2 二进制计数规则
1.3.3 简单的二进制运算规则
1.3.4 二进制数的分解
1.3.5 十进制数转换为二进制数
1.4 还有哪些进制
1.4.1 神奇的八卦：八进制
1.4.2 钟表使用的十二进制
1.4.3 半斤八两：十六进制
1.4.4 60年一个甲子：六十进制
1.4.5 各种进制之间的转换
1.4.6 二进制与八进制、十六进制的转换


第2章 神奇的素数
2.1 怎么判断素数
2.1.1 什么是素数
2.1.2 验证素数
2.1.3 寻找素数的算法
2.1.4 已被证明的素数定理
2.2 孪生素数
2.2.1 什么是孪生素数
2.2.2 孪生素数的公式
2.2.3 中国剩余定理
2.2.4 孪生素数分布情况
2.3 使用素数的RSA算法
2.3.1 什么是RSA
2.3.2 RSA算法基础
2.3.3 RSA算法实践
2.3.4 RSA应用：数字签名
2.3.5 RSA被破解的可能性
2.4 哥德巴赫猜想
2.4.1 哥德巴赫猜想是什么
2.4.2 数值验证
2.5 梅森素数
2.5.1 什么是梅森素数
2.5.2 已知的梅森素数列表


第3章 递归——自己调用自己
3.1 从前有座山，山里有座庙
3.1.1 老和尚讲的故事
3.1.2 德罗斯特效应
3.1.3 什么是递归
3.1.4 用递归能解决哪些问题
3.1.5 一个简单例子：求最大公约数
3.2 用递归计算阶乘
3.2.1 阶乘该怎么计算
3.2.2 阶乘的递归计算方法
3.2.3 递归的过程
3.2.4 递归的本质：缩小问题规模
3.3 汉诺塔
3.3.1 古老的传说
3.3.2 从两个盘考虑
3.3.3 找出递归结构
3.3.4 实现程序
3.3.5 究竟需要移动多少次
3.4 斐波那契数列
3.4.1 兔子的家族
3.4.2 从最初几月数据中找规律
3.4.3 斐波那契数列
3.4.4 神奇的魔八方


第4章 排列组合——让数选边站队
4.1 把所有情况都列出来
4.1.1 从0还是1开始
4.1.2 赛程安排
4.2 乘法原理
4.2.1 行程安排的问题
4.2.2 乘法原理适用条件
4.2.3 棋盘上棋子的放法
4.2.4 买彩票保证中奖的方法
4.3 加法原理
4.3.1 仍然是行程问题
4.3.2 总结出的加法原理
4.3.3 骰子出现偶数的次数
4.4 排列与组合的关系
4.4.1 排列
4.4.2 组合
4.4.3 排列与组合的联系
4.4.4 可重排列
4.5 计算机中的字符编码
4.5.1 ASCII码能表示的字符数量
4.5.2 能表示更大范围的编码
4.6 密码的长度
4.6.1 容易破解的密码
4.6.2 多长的密码才安全
4.6.3 密码中使用的字符数量也很关键


第5章 余数——数据分组
5.1 复习小学的余数
5.1.1 自然数的余数
5.1.2 余数的性质
5.1.3 用余数进行分组
5.2 日历中的数学
5.2.1 n天后是星期几
5.2.2 下月的今天是星期几
5.2.3 10年后的“今天”是星期几
5.3 心灵感应魔术
5.3.1 一个小魔术
5.3.2 魔术师是怎么猜出来的
5.4 奇偶校验
5.4.1 不可靠的网络传输
5.4.2 用奇偶校验检查错误
5.5 吕洞宾不能坐首位
5.5.1 座位安排
5.5.2 试排座位找规律
5.5.3 西方的约瑟夫环
5.5.4 用数学方法解约瑟夫环
5.6 智叟分牛
5.6.1 遗产分配难题
5.6.2 智叟给出的分配方案
5.6.3 分配原理


第6章 概率——你运气好吗
6.1 初中学习过的概率
6.1.1 谁先开球
6.1.2 用程序模拟抛硬币
6.1.3 什么是概率
6.1.4 必然事件与不可能事件
6.1.5 概率的基本性质
6.2 百枚钱币鼓士气
6.2.1 狄青的计谋
6.2.2 全为正面的概率是多少
6.2.3 必然还是偶然
6.3 庄家的胜率是多少
6.3.1 一个看似公平的游戏
6.3.2 庄家能赢钱吗
6.3.3 庄家盈利比率
6.3.4 游戏参与者获胜的概率
6.4 你能中奖吗
6.4.1 想中大奖吗
6.4.2 计算中奖概率
6.5 渔塘中有多少条鱼
6.5.1 该怎么估算渔塘中的鱼
6.5.2 用概率来估算
6.5.3 用概率方法求π值


第7章 翻一番是多少
7.1 翻番的概念
7.1.1 什么是翻番
7.1.2 翻倍的概念
7.1.3 计算倍数和番数
7.2 复利的威力
7.2.1 利润——投资回报
7.2.2 认识单利
7.2.3 认识复利
7.2.4 计算投资回报的程序
7.2.5 忘还钱的信用卡
7.2.6 爱因斯坦的72法则
7.3 对折纸张
7.3.1 有趣的问题：纸张对折
7.3.2 100米长的纸能对折几次
7.3.3 计算对折次数的程序
7.4 一棋盘的麦子
7.4.1 舍罕王的赏赐
7.4.2 需要多少麦粒
7.5 折半法的运用
7.5.1 翻番的逆运算
7.5.2 找出假硬币
7.5.3 编写程序找出假硬币
7.5.4 折半法在查找中的应用


第8章 数理逻辑——非此即彼
8.1 逻辑的重要性
8.1.1 模棱两可的表述
8.1.2 肯定或否定
8.1.3 程序中的逻辑判断
8.2 命题逻辑
8.2.1 什么是命题
8.2.2 命题的逻辑形式
8.2.3 简单命题
8.2.4 复合命题
8.2.5 复合命题的联结词
8.3 布尔逻辑
8.3.1 逻辑或
8.3.2 逻辑与
8.3.3 逻辑非
8.3.4 逻辑异或
8.3.5 二进制位运算
8.4 考虑到各种可能了吗
8.4.1 逻辑重叠的实例
8.4.2 逻辑遗漏的实例
8.4.3 用数轴确定边界
8.5 用卡诺图简化逻辑函数
8.5.1 什么是卡诺图
8.5.2 三变量卡诺图
8.5.3 四变量卡诺图
8.5.4 卡诺图化简
8.5.5 卡诺图中的相邻


第9章 推理——逻辑的应用
9.1 演绎推理
9.1.1 认识演绎推理点
9.1.2 三段论
9.1.3 选言推理
9.1.4 假言推理
9.1.5 关系推理
9.1.6 演绎推理综合实例
9.2 归纳推理
9.2.1 什么是归纳推理
9.2.2 完全归纳推理
9.2.3 不完全归纳推理
9.3 足球比赛的得分
9.3.1 粗心的记分员
9.3.2 从已有数据推算出比分


第10章 几何图形构造
10.1 花盆摆放问题
10.1.1 10盆花摆成5行，每行4盆
10.1.2 转变思路，找出答案
10.1.3 升级问题（10盆花摆10行，每行3盆）
10.2 残缺的棋盘能补上吗？
10.2.1 被切割的棋盘
10.2.2 能拼接出残缺棋盘吗
10.3 线条哪里去了？
10.3.1 神奇的魔术
10.3.2 解析丢失的线条
10.4 图形剪拼
10.4.1 均分三角形
10.4.2 拼接正方形


第11章 统筹规划
11.1 认识统筹规划
11.1.1 田忌赛马
11.1.2 为什么会赢
11.2 生活中的统筹规划
11.2.1 匆忙的早晨
11.2.2 如何节约运输成本
11.3 著名的背包问题
11.3.1 什么是背包问题
11.3.2 用递归程序解决背包问题
11.3.3 用穷举法解决背包问题
```

### [程序员的数学 第2版(图灵出品)](https://item.jd.com/12831612.html)
```text
第 1章 0 的故事——无即是有



本章学习内容　2



小学一年级的回忆　2



10进制计数法　3



什么是10进制计数法　3



分解2503　3



2进制计数法　4



什么是2进制计数法　4



分解1100　5



基数转换　6



计算机中为什么采用2　进制计数法　8



按位计数法　10



什么是按位计数法　10



不使用按位计数法的罗马数字　11



指数法则　12



10的0次方是什么　12



10–1是什么　13



规则的扩展　14



对20进行思考　14



2–1是什么　15



0所起的作用　16



0的作用：占位　16



0的作用：统一标准，简化规则　16



日常生活中的0　17



人类的极限和构造的发现　18



重温历史进程　18



为了超越人类的极限　19



本章小结　20



第　2章 逻辑——真与假的二元世界



本章学习内容　22



为何逻辑如此重要　22



逻辑是消除歧义的工具　22



致对逻辑持否定意见的读者　23



乘车费用问题—兼顾完整性和排他性　23



收费规则　23



命题及其真假　24



有没有“遗漏”　24



有没有“重复”　25



画一根数轴辅助思考　26



注意边界值　27



兼顾完整性和排他性　28



使用if　语句分解问题　28



逻辑的基本是两个分支　29



建立复杂命题　29



逻辑非—不是A　30



逻辑与—A并且B　32



逻辑或—A或者B　34



异或—A或者B（但不都满足）　37



相等—A和B相等　39



蕴涵—若A则B　40



囊括所有了吗　45



德摩根定律　46



德摩根定律是什么　46



对偶性　47



卡诺图　48



二灯游戏　48



首先借助逻辑表达式进行思考　49



学习使用卡诺图　50



三灯游戏　52



包含未定义的逻辑　54



带条件的逻辑与（&&）　55



带条件的逻辑或（||）　57



三值逻辑中的否定（!）　58



三值逻辑的德摩根定律　59



囊括所有了吗　60



本章小结　60



第3章　余数——周期性和分组



本章学习内容　64



星期数的思考题(1)　64



思考题（100　天以后是星期几）　64



思考题答案　65



运用余数思考　65



余数的力量—将较大的数字除一次就能分组　65



星期数的思考题(2)　66



思考题（10100　天以后是星期几）　66



提示：可以直接计算吗　67



思考题答案　67



发现规律　68



直观地把握规律　68



乘方的思考题　70



思考题（1　234 567987 654 321）　70



提示：通过试算找出规律　70



思考题答案　70



回顾：规律和余数的关系　71



通过黑白棋通信　71



思考题　71



提示　73



思考题答案　73



奇偶校验　74



奇偶校验位将数字分为2　个集合　74



寻找恋人的思考题　74



思考题（寻找恋人）　74



提示：先试算较小的数　75



思考题答案　75



回顾　76



铺设草席的思考题　77



思考题（在房间里铺设草席）　77



提示：先计算一下草席数　78



思考题答案　78



回顾　79



一笔画的思考题　79



思考题（哥尼斯堡七桥问题）　79



提示：试算一下　80



提示：考虑简化一下　81



提示：考虑入口和出口　82



思考题答案　82



奇偶校验　85



本章小结　86



第4章　数学归纳法——如何征服无穷数列



本章学习内容　88



高斯求和　88



思考题（存钱罐里的钱）　88



思考一下　89



小高斯的解答　89



讨论一下小高斯的解答　89



归纳　91



数学归纳法—如何征服无穷数列　91



0　以上的整数的断言　92



小高斯的断言　93



什么是数学归纳法　93



试着征服无穷数列　94



用数学归纳法证明小高斯的断言　95



求出奇数的和—数学归纳法实例　96



通过数学归纳法证明　96



通过数学归纳法证明　97



图形化说明　98



黑白棋思考题—错误的数学归纳法　99



思考题（黑白棋子的颜色）　99



提示：不要为图所惑　100



思考题答案　101



编程和数学归纳法　101



通过循环表示数学归纳法　101



循环不变式　104



本章小结　107



第5章　排列组合——解决计数问题的方法



本章学习内容　110



计数—与整数的对应关系　110



何谓计数　110



注意“遗漏”和“重复”　111



植树问题—不要忘记0　111



植树问题思考题　111



加法法则　115



加法法则　115



乘法法则　118



乘法法则　118



置换　121



置换　121



归纳一下　122



思考题（扑克牌的摆法）　123



排列　124



排列　124



归纳一下　126



树形图—能够认清本质吗　128



组合　130



组合　130



归纳一下　131



置换、排列、组合的关系　133



思考题练习　134



重复组合　135



也要善于运用逻辑　137



本章小结　140



第6章　递归——自己定义自己



本章学习内容　144



汉诺塔　144



思考题（汉诺塔）　145



提示：先从小汉诺塔着手　145



思考题答案　148



求出解析式　150



解出汉诺塔的程序　151



找出递归结构　152



再谈阶乘　154



阶乘的递归定义　154



思考题（和的定义）　155



递归和归纳　156



斐波那契数列　156



思考题（不断繁殖的动物）　157



斐波那契数列　159



帕斯卡三角形　162



什么是帕斯卡三角形　162



递归定义组合数　165



组合的数学理论解释　165



递归图形　167



以递归形式画树　167



实际作图　168



谢尔平斯基三角形　170



本章小结　171



第7章　指数爆炸——如何解决复杂问题



本章学习内容　174



什么是指数爆炸　174



思考题（折纸问题）　174



指数爆炸　177



倍数游戏—指数爆炸引发的难题　178



程序的设置选项　178



不能认为是“有限的”就不假思索　180



二分法查找—利用指数爆炸进行查找　180



寻找犯人的思考题　180



提示：先思考人数较少的情况　181



思考题答案　182



找出递归结构以及递推公式　183



二分法查找和指数爆炸　185



对数—掌握指数爆炸的工具　186



什么是对数　187



对数和乘方的关系　187



以2为底的对数　188



以2为底的对数练习　189



对数图表　189



指数法则和对数　191



对数和计算尺　192



密码—利用指数爆炸加密　195



暴力破解法　195



字长和安全性的关系　196



如何处理指数爆炸　197



理解问题空间的大小　197



四种处理方法　198



本章小结　199



第8章　不可解问题——不可解的数、无法编写的程序



本章学习内容　202



反证法　202



什么是反证法　202



质数思考题　204



反证法的注意事项　205



可数　205



什么是可数　205



可数集合的例子　206



有没有不可数的集合　208



对角论证法　209



所有整数数列的集合是不可数的　209



所有实数的集合是不可数的　213



所有函数的集合也是不可数的　214



不可解问题　215



什么是不可解问题　215



存在不可解问题　216



思考题　217



停机问题　218



停机　218



处理程序的程序　219



什么是停机问题　219



停机问题的证明　221



写给尚未理解的读者　224



不可解问题有很多　226



本章小结　226



第9章　什么是程序员的数学——总结篇



本章学习内容　230



何为解决问题　233



认清模式，进行抽象化　233



由不擅长催生出的智慧　233



幻想法则　234



程序员的数学　235



附录　迈向机器学习的第 一步



本附录学习内容　238



什么是机器学习　239



受到广泛关注的机器学习技术　239



机器学习是随着时代发展诞生的技术　239



预测问题和分类问题　240



预测问题　240



分类问题　243



感知器　245



什么是感知器　245



加权求和　247



激活函数　249



感知器小结　250



机器学习是如何“学习”的　250



学习的流程　250



训练数据与测试数据　251



损失函数　252



梯度下降法　254



作为程序员要做些什么　256



神经网络　256



什么是神经网络　256



误差反向传播法　258



深度学习和强化学习　259



人类就这样没用了吗　260



附录小结　261
```

### [程序员的数学3 线性代数(图灵出品)](https://item.jd.com/11891058.html)

```text
第0章　动机 1
0．1　空间想象给我们带来的直观感受 1
0．2　有效利用线性近似的手段 2
第1章　用空间的语言表达向量、矩阵和行列式 5
1．1　向量与空间 5
1．1．1　最直接的定义：把数值罗列起来就是向量 6
1．1．2　“空间”的形象 9
1．1．3　基底 11
1．1．4　构成基底的条件 16
1．1．5　维数 18
1．1．6　坐标 19
1．2　矩阵和映射 19
1．2．1　暂时的定义 19
1．2．2　用矩阵来表达各种关系（1） 24
1．2．3　矩阵就是映射！ 25
1．2．4　矩阵的乘积=映射的合成 28
1．2．5　矩阵运算的性质 31
1．2．6　矩阵的乘方=映射的迭代 35
1．2．7　零矩阵、单位矩阵、对角矩阵 37
1．2．8　逆矩阵=逆映射 44
1．2．9　分块矩阵 47
1．2．10　用矩阵表示各种关系（2） 53
1．2．11　坐标变换与矩阵 55
1．2．12　转置矩阵=??? 63
1．2．13　补充（1）：时刻注意矩阵规模 64
1．2．14　补充（2）：从矩阵的元素的角度看 67
1．3　行列式与扩大率 68
1．3．1　行列式=体积扩大率 68
1．3．2　行列式的性质 73
1．3．3　行列式的计算方法（1）：计算公式▽ 80
1．3．4　行列式的计算方法（2）：笔算法▽ 87
1．3．5　补充：行列式按行（列）展开与逆矩阵▽ 91
第2章　秩、逆矩阵、线性方程组——溯因推理 95
2．1　问题设定：逆问题 95
2．2　良性问题（可逆矩阵） 97
2．2．1　可逆性与逆矩阵 97
2．2．2　线性方程组的解法（系数矩阵可逆的情况）▽ 97
2．2．3　逆矩阵的计算方法▽ 107
2．2．4　初等变换▽ 110
2．3　恶性问题 115
2．3．1　恶性问题示例 115
2．3．2　问题的恶劣程度——核与像 120
2．3．3　维数定理 122
2．3．4　用式子表示“压缩扁平化”变换（线性无关、线性相关） 126
2．3．5　线索的实际个数（秩） 130
2．3．6　秩的求解方法（1）——悉心观察 137
2．3．7　秩的求解方法（2）——笔算 142
2．4　良性恶性的判定（逆矩阵存在的条件） 149
2．4．1　重点是“是不是压缩扁平化映射” 149
2．4．2　与可逆性等价的条件 150
2．4．3　关于可逆性的小结 151
2．5　针对恶性问题的对策 152
2．5．1　求出所有能求的结果（1）理论篇 152
2．5．2　求出所有能求的结果（2）实践篇 155
2．5．3　最小二乘法 166
2．6　现实中的恶性问题（接近奇异的矩阵） 167
2．6．1　问题源于哪里 167
2．6．2　对策示例——提克洛夫规范化 170
第3章　计算机上的计算（1）——LU 分解 173
3．1　引言 173
3．1．1　切莫小看数值计算 173
3．1．2　关于本书中的程序 174
3．2　热身：加减乘运算 174
3．3　LU分解 176
3．3．1　定义 176
3．3．2　分解能带来什么好处 178
3．3．3　LU分解真的可以做到吗 178
3．3．4　LU分解的运算量如何 180
3．4　LU分解的步骤（1）一般情况 182
3．5　利用LU分解求行列式值 186
3．6　利用LU分解求解线性方程组 187
3．7　利用LU分解求逆矩阵 191
3．8　LU分解的步骤（2）意外发生的情况 192
3．8．1　需要整理顺序的情况 192
3．8．2　重新整理顺序也无济于事的状况 196
第4章　特征值、对角化、Jordan标准型——判断是否有失控的危险 197
4．1　问题的提出：稳定性 197
4．2　一维的情况 202
4．3　对角矩阵的情况 203
4．4　可对角化的情况 205
4．4．1　变量替换 205
4．4．2　变量替换的求法 213
4．4．3　从坐标变换的角度来解释 215
4．4．4　从乘方的角度来解释 219
4．4．5　结论：关键取决于特征值的绝对值 220
4．5　特征值、特征向量 220
4．5．1　几何学意义 220
4．5．2　特征值、特征向量的性质 225
4．5．3　特征值的计算：特征方程 232
4．5．4　特征向量的计算▽ 240
4．6　连续时间系统 246
4．6．1　微分方程 247
4．6．2　一阶情况 250
4．6．3　对角矩阵的情况 250
4．6．4　可对角化的情况 252
4．6．5　结论：特征值（的实部）的符号是关键 252
4．7　不可对角化的情况 255
4．7．1　首先给出结论 255
4．7．2　就算不能对角化——Jordan标准型 256
4．7．3　Jordan标准型的性质 257
4．7．4　利用Jordan标准型解决初始值问题（失控判定的最终结论） 264
4．7．5　化Jordan标准型的方法 271
4．7．6　任何方阵均可化为Jordan标准型的证明 279
第5章　计算机上的计算（2）——特征值算法 299
5．1　概要 299
5．1．1　和笔算的不同之处 299
5．1．2　伽罗华理论 300
5．1．3　5×5以上的矩阵的特征值不存在通用的求解步骤！ 302
5．1．4　有代表性的特征值数值算法 303
5．2　Jacobi方法 303
5．2．1　平面旋转 304
5．2．2　通过平面旋转进行相似变换 306
5．2．3　计算过程的优化 309
5．3　幂法原理 310
5．3．1　求绝对值最大的特征值 310
5．3．2　求绝对值最小的特征值 311
5．3．3　QR分解 312
5．3．4　求所有特征值 316
5．4　QR方法 318
5．4．1　QR方法的原理 319
5．4．2　Hessenberg矩阵 321
5．4．3　Householder方法 322
5．4．4　Hessenberg矩阵的QR迭代 325
5．4．5　原点位移、降阶 327
5．4．6　对称矩阵的情况 327
5．5　反幂法 328
附录A　希腊字母表 330
附录B　复数 331
附录C　关于基底的补充说明 336
附录D　微分方程的解法 341
D．1　dx/dt = f(x) 型 341
D．2　dx/dt = ax + g(t) 型 342
附录E　内积、对称矩阵、正交矩阵 346
E．1　内积空间 346
E．1．1　模长 346
E．1．2　正交 347
E．1．3　内积 347
E．1．4　标准正交基 349
E．1．5　转置矩阵 351
E．1．6　复内积空间 351
E．2　对称矩阵与正交矩阵——实矩阵的情况 352
E．3　埃尔米特矩阵与酉矩阵——复矩阵的情况 353
附录F　动画演示程序的使用方法 354
F．1　执行结果 354
F．2　准备工作 354
F．3　使用方法 355
参考文献 357
```

### [程序员的数学2 概率统计(图灵出品)](https://item.jd.com/11771007.html)

```text
第1部分　聊聊概率这件事
第1章　概率的定义　　3
1.1　概率的数学定义　　3
1.2　三扇门（蒙提霍尔问题） ——飞艇视角　　4
1.2.1　蒙提霍尔问题　　5
1.2.2　正确答案与常见错误　　6
1.2.3　以飞艇视角表述　　6
1.3　三元组（Ω, F, P） ——上帝视角　　9
1.4　随机变量　　13
1.5　概率分布　　17
1.6　适于实际使用的简记方式　　19
1.6.1　随机变量的表示方法　　19
1.6.2　概率的表示方法　　20
1.7　Ω是幕后角色　　21
1.7.1　不必在意Ω究竟是什么　　21
1.7.2　Ω的习惯处理方式　　22
1.7.3　不含Ω（不含上帝视角）的概率论　　23
1.8　一些注意事项　　23
1.8.1　想做什么　　23
1.8.2　因为是面积……　　24
1.8.3　解释　　26
第2章　多个随机变量之间的关系　　29
2.1　各县的土地使用情况（面积计算的预热）　　29
2.1.1　不同县、不同用途的统计（联合概率与边缘概率的预热）　　30
2.1.2　特定县、特定用途的比例（条件概率的预热）　　31
2.1.3　倒推比例（贝叶斯公式的预热）　　32
2.1.4　比例相同的情况（独立性的预热）　　34
2.1.5　预热结束　　38
2.2　联合概率与边缘概率　　38
2.2.1　两个随机变量　　38
2.2.2　三个随机变量　　41
2.3　条件概率　　42
2.3.1　条件概率的定义　　42
2.3.2　联合分布、边缘分布与条件分布的关系　　45
2.3.3　即使条件中使用的不是等号也一样适用　　50
2.3.4　三个或更多的随机变量　　51
2.4　贝叶斯公式　　55
2.4.1　问题设置　　56
2.4.2　贝叶斯的作图曲　　57
2.4.3　贝叶斯公式　　61
2.5　独立性　　63
2.5.1　事件的独立性（定义）　　64
2.5.2　事件的独立性（等价表述）　　67
2.5.3　随机变量的独立性　　70
2.5.4　三个或更多随机变量的独立性（需多加注意）　　73
第3章　离散值的概率分布　　79
3.1　一些简单的例子　　79
3.2　二项分布　　82
3.2.1　二项分布的推导　　82
3.2.2　补充：排列nPk、组合nCk　　83
3.3　期望值　　85
3.3.1　期望值的定义　　85
3.3.2　期望值的基本性质　　87
3.3.3　期望值乘法运算的注意事项　　91
3.3.4　期望值不存在的情况　　93
3.4　方差与标准差　　99
3.4.1　即使期望值相同　　99
3.4.2　方差即“期望值离散程度”的期望值　　100
3.4.3　标准差　　102
3.4.4　常量的加法、乘法及标准化　　104
3.4.5　各项独立时，和的方差等于方差的和　　108
3.4.6　平方的期望值与方差　　110
3.5　大数定律　　112
3.5.1　独立同分布　　114
3.5.2　平均值的期望值与平均值的方差　　116
3.5.3　大数定律　　117
3.5.4　大数定律的相关注意事项　　118
3.6　补充内容：条件期望与最小二乘法　　120
3.6.1　条件期望的定义　　120
3.6.2　最小二乘法　　121
3.6.3　上帝视角　　122
3.6.4　条件方差　　123
第4章　连续值的概率分布　　127
4.1　渐变色打印问题（密度计算的预热）　　128
4.1.1　用图表描述油墨的消耗量（累积分布函数的预热）　　128
4.1.2　用图表描述油墨的打印浓度（概率密度函数预热）　　129
4.1.3　拉伸打印成品对油墨浓度的影响（变量变换的预热）　　133
4.2　概率为零的情况　　136
4.2.1　出现概率恰好为零的情况　　137
4.2.2　概率为零将带来什么问题　　139
4.3　概率密度函数　　140
4.3.1　概率密度函数　　140
4.3.2　均匀分布　　146
4.3.3　概率密度函数的变量变换　　147
4.4　联合分布·边缘分布·条件分布　　152
4.4.1　联合分布　　152
4.4.2　本小节之后的阅读方式　　155
4.4.3　边缘分布　　155
4.4.4　条件分布　　159
4.4.5　贝叶斯公式　　162
4.4.6　独立性　　163
4.4.7　任意区域的概率·均匀分布·变量变换　　166
4.4.8　实数值与离散值混合存在的情况　　174
4.5　期望值、方差与标准差　　174
4.5.1　期望值　　175
4.5.2　方差·标准差　　179
4.6　正态分布与中心极限定理　　180
4.6.1　标准正态分布　　181
4.6.2　一般正态分布　　184
4.6.3　中心极限定理　　187
第5章　协方差矩阵、多元正态分布与椭圆　　195
5.1　协方差与相关系数　　196
5.1.1　协方差　　196
5.1.2　协方差的性质　　199
5.1.3　分布倾向的明显程度与相关系数　　200
5.1.4　协方差与相关系数的局限性　　206
5.2　协方差矩阵　　208
5.2.1　协方差矩阵=方差与协方差的一览表　　208
5.2.2　协方差矩阵的向量形式表述　　209
5.2.3　向量与矩阵的运算及期望值　　212
5.2.4　向量值随机变量的补充说明　　215
5.2.5　协方差矩阵的变量变换　　217
5.2.6　任意方向的发散程度　　218
5.3　多元正态分布　　220
5.3.1　多元标准正态分布　　220
5.3.2　多元一般正态分布　　223
5.3.3　多元正态分布的概率密度函数　　228
5.3.4　多元正态分布的性质　　230
5.3.5　截面与投影　　232
5.3.6　补充知识：卡方分布　　239
5.4　协方差矩阵与椭圆的关系　　242
5.4.1　（实例一）单位矩阵与圆　　242
5.4.2　（实例二）对角矩阵与椭圆　　244
5.4.3　（实例三）一般矩阵与倾斜的椭圆　　247
5.4.4　协方差矩阵的局限性　　251
第2部分　探讨概率的应用
第6章　估计与检验　　257
6.1　估计理论　　257
6.1.1　描述统计与推断统计　　257
6.1.2　描述统计　　258
6.1.3　如何理解推断统计中的一些概念　　260
6.1.4　问题设定　　264
6.1.5　期望罚款金额　　265
6.1.6　多目标优化　　266
6.1.7　（策略一）减少候选项——最小方差无偏估计　　267
6.1.8　（策略二）弱化最优定义——最大似然估计　　269
6.1.9　（策略三）以单一数值作为评价基准——贝叶斯估计　　272
6.1.10　策略选择的相关注意事项　　275
6.2　检验理论　　276
6.2.1　检验理论中的逻辑　　276
6.2.2　检验理论概述　　278
6.2.3　简单假设　　279
6.2.4　复合假设　　282
第7章　伪随机数　　285
7.1　伪随机数的基础知识　　285
7.1.1　随机数序列　　285
7.1.2　伪随机数序列　　286
7.1.3　典型应用：蒙特卡罗方法　　287
7.1.4　相关主题：密码理论中的伪随机数序列·低差异序列　　289
7.2　遵从特定分布的随机数的生成　　291
7.2.1　遵从离散值分布的随机数的生成　　292
7.2.2　遵从连续值分布的随机数的生成　　293
7.2.3　遵从正态分布的随机数的生成　　296
7.2.4　补充知识：三角形内及球面上的均匀分布　　298
第8章　概率论的各类应用　　305
8.1　回归分析与多变量分析　　305
8.1.1　通过最小二乘法拟合直线　　305
8.1.2　主成分分析　　312
8.2　随机过程　　319
8.2.1　随机游走　　321
8.2.2　卡尔曼滤波器　　326
8.2.3　马尔可夫链　　331
8.2.4　关于随机过程的一些补充说明　　342
8.3　信息论　　343
8.3.1　熵　　343
8.3.2　二元熵　　347
8.3.3　信源编码　　349
8.3.4　信道编码　　352
附录A　本书涉及的数学基础知识　　359
A.1　希腊字母　　359
A.2　数　　359
A.2.1　自然数·整数　　359
A.2.2　有理数·实数　　359
A.2.3　复数　　360
A.3　集合　　360
A.3.1　集合的表述方式　　360
A.3.2　无限集的大小　　361
A.3.3　强化练习　　361
A.4　求和符号∑　　362
A.4.1　定义与基本性质　　362
A.4.2　双重求和　　364
A.4.3　范围指定　　366
A.4.4　等比数列　　366
A.5　指数与对数　　368
A.5.1　指数函数　　368
A.5.2　高斯积分　　371
A.5.3　对数函数　　374
A.6　内积与长度　　377
附录B　近似公式与不等式　　381
B.1　斯特林公式　　381
B.2　琴生不等式　　381
B.3　吉布斯不等式　　384
B.4　马尔可夫不等式与切比雪夫不等式　　385
B.5　切尔诺夫界　　386
B.6　闵可夫斯基不等式与赫尔德不等式　　387
B.7　算术平均值≥ 几何平均值≥ 调和平均值　　390
附录C　概率论的补充知识　　393
C.1　随机变量的收敛　　393
C.1.1　依概率1收敛　　393
C.1.2　依概率收敛　　395
C.1.3　均方收敛　　396
C.1.4　依分布收敛　　396
C.2　特征函数　　397
C.3　KL散度与大偏差原理　　399
参考文献　　404
```

### [普林斯顿微积分读本（修订版）](https://www.ituring.com.cn/book/1623)
```text
目录
版权声明	阅读
献词	阅读
译者序	阅读
前言	阅读
致谢	阅读
第 1 章　函数、图像和直线	阅读
第 2 章　三角学回顾	阅读
第 3 章　极限导论	阅读
第 4 章　求解多项式的极限问题	阅读
第 5 章　连续性和可导性	
第 6 章　求解微分问题	
第 7 章　三角函数的极限和导数	
第 8 章　隐函数求导和相关变化率	
第 9 章　指数函数和对数函数	
第 10 章　反函数和反三角函数	
第 11 章　导数和图像	
第 12 章　绘制函数图像	
第 13 章　最优化和线性化	
第 14 章　洛必达法则及极限问题总结	
第 15 章　积分	
第 16 章　定积分	
第 17 章　微积分基本定理	
第 18 章　积分的方法 I	
第 19 章　积分的方法 II	
第 20 章　反常积分：基本概念	
第 21 章　反常积分：如何解题	
第 22 章　数列和级数：基本概念	
第 23 章　求解级数问题	
第 24 章　泰勒多项式、泰勒级数和幂级数导论	
第 25 章　求解估算问题	
第 26 章　泰勒级数和幂级数：如何解题	
第 27 章　参数方程和极坐标	
第 28 章　复数	
第 29 章　体积、弧长和表面积	
第 30 章　微分方程	
附录 A　极限及其证明	
附录 B　估算积分	
符号列表
```